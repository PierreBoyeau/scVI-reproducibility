{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "from chart_studio.plotly import plot, iplot\n",
    "\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scvi.dataset import PbmcDataset\n",
    "from scvi.models import VAE, IAVAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.utils import (\n",
    "    demultiply,\n",
    "    make_dir_if_necessary,\n",
    "    predict_de_genes,\n",
    "    save_fig,\n",
    "    save_pickle,\n",
    "    load_pickle,\n",
    "    compute_hdi\n",
    ")\n",
    "from scvi_utils import (\n",
    "    estimate_de_proba,\n",
    "    estimate_lfc_density,\n",
    "    estimate_lfc_mean,\n",
    "    train_model,\n",
    "    multi_train_estimates,\n",
    ")\n",
    "from R_interop import all_predictions, all_de_predictions\n",
    "\n",
    "\n",
    "N_EPOCHS = 200\n",
    "DELTA = 0.5\n",
    "# SIZES = [5, 10, 20, 30, 50, 100]\n",
    "MODE = \"cloud\"\n",
    "SIZE = 100\n",
    "SIZES = [SIZE]\n",
    "N_SIZES = len(SIZES)\n",
    "\n",
    "Q0 = 5e-2\n",
    "N_TRAININGS = 5\n",
    "N_PICKS = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "PATH_TO_SCRIPTS = \"/home/ubuntu/conquer_comparison/scripts\"\n",
    "DIR_PATH = \"lfc_estimates/pbmc\"\n",
    "make_dir_if_necessary(DIR_PATH)\n",
    "\n",
    "label_a = 0\n",
    "label_b = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "\n",
    "py.sign_in(\"pierreboyeau\", \"2wvdnWZ2Qut1zD07ADVy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PbmcDataset()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(\n",
    "    dataset.labels.squeeze(), return_counts=True\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(dict(counts=counts_elements, cell_types=dataset.cell_types))\n",
    "fig = px.scatter(df, y=\"counts\", x=\"cell_types\")\n",
    "fig.show()\n",
    "n_genes = dataset.nb_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cell types: \", dataset.cell_types)\n",
    "print('Gene names: ', dataset.gene_names)\n",
    "\n",
    "microarray_info = dataset.de_metadata.set_index('ENSG')\n",
    "microarray_info = microarray_info.loc[dataset.gene_names]\n",
    "\n",
    "display(dataset.de_metadata.head())\n",
    "print(dataset.de_metadata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = len(dataset)\n",
    "labels = dataset.labels.squeeze()\n",
    "# interesting_indices = np.where((labels == label_a) | (labels == label_b))[0]\n",
    "# TEST_INDICES = np.random.permutation(interesting_indices)[:800]\n",
    "TEST_INDICES = np.random.permutation(len(dataset))[:3000]\n",
    "\n",
    "x_test, y_test = dataset.X[TEST_INDICES, :], dataset.labels[TEST_INDICES, :].squeeze()\n",
    "\n",
    "data_path = os.path.join(DIR_PATH, 'data.npy')\n",
    "labels_path = os.path.join(DIR_PATH, 'labels.npy')\n",
    "\n",
    "np.save(\n",
    "    data_path,\n",
    "    np.array(x_test.todense()).squeeze().astype(int)\n",
    ")\n",
    "np.savetxt(\n",
    "    labels_path,\n",
    "    y_test.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, y_all = dataset.X, dataset.labels.squeeze()\n",
    "\n",
    "data_all_path = os.path.join(DIR_PATH, 'data_all.npy')\n",
    "labels_all_path = os.path.join(DIR_PATH, 'labels_all.npy')\n",
    "\n",
    "np.save(\n",
    "    data_all_path,\n",
    "    np.array(x_all.todense()).squeeze().astype(int)\n",
    ")\n",
    "np.savetxt(\n",
    "    labels_all_path,\n",
    "    y_all.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_STOPPING_KWARGS = {\n",
    "    \"early_stopping_metric\": \"elbo_ratio_loss\",\n",
    "    \"save_best_state_metric\": \"elbo_ratio_loss\",\n",
    "    \"patience\": 20,\n",
    "    \"threshold\": 0,\n",
    "    \"reduce_lr_on_plateau\": True,\n",
    "    \"lr_patience\": 10,\n",
    "    \"lr_factor\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_params = dict(\n",
    "    iaf=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    "    iaf_k5=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf_k5=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    ")\n",
    "train_params = dict(\n",
    "    iaf=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    mf=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    base=dict(\n",
    "        ratio_loss=True,\n",
    "#         test_indices=TEST_INDICES,\n",
    "#         frequency=1,\n",
    "#         early_stopping_kwargs=EARLY_STOPPING_KWARGS,\n",
    "    ),\n",
    "    iaf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5),\n",
    "    mf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5),\n",
    ")\n",
    "train_fn_params = dict(\n",
    "    iaf=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    mf=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    base=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    iaf_k5=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    mf_k5=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions = all_predictions(\n",
    "    filename=os.path.join(DIR_PATH, \"all_predictions_all_data2.pickle\"),\n",
    "    n_genes=n_genes,\n",
    "    n_picks=N_PICKS,\n",
    "    sizes=[SIZE],\n",
    "#     data_path=data_path,\n",
    "#     labels_path=labels_path,\n",
    "    data_path=data_all_path,\n",
    "    labels_path=labels_all_path,\n",
    "    path_to_scripts=PATH_TO_SCRIPTS,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b,\n",
    "    all_nature=False\n",
    ")\n",
    "\n",
    "other_predictions = all_de_predictions(\n",
    "    other_predictions, significance_level=Q0, delta=DELTA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions[\"mast\"] = mast_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case MAST does not work\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.numpy2ri\n",
    "import warnings\n",
    "import numpy as np\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MAST(object):\n",
    "    def __init__(self, A, B, data, labels, cluster):\n",
    "        \"\"\"\n",
    "        A: number of cells in the first cluster\n",
    "        B: number of cells in the second cluster\n",
    "        data: dataset to look at\n",
    "        labels: clusters\n",
    "        cluster: list that tells which cluster to test ex. (0, 4)\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.cluster = cluster\n",
    "        warnings.filterwarnings(\"ignore\", category=RRuntimeWarning)\n",
    "        rpy2.robjects.numpy2ri.activate()\n",
    "        ro.r[\"library\"](\"RcppCNPy\")\n",
    "        ro.r[\"library\"](\"MAST\")\n",
    "        ro.r[\"library\"](\"BiocParallel\")\n",
    "        ro.r(\"BiocParallel::register(BiocParallel::MulticoreParam())\")\n",
    "        \n",
    "        self.X_train = np.load(self.data)\n",
    "        self.c_train = np.loadtxt(self.labels)\n",
    "        \n",
    "        # loading data\n",
    "        ro.r(str(\"\"\"fmat <- npyLoad(\"*\"\"\")[:-1] + self.data + str(\"\"\"*\", \"integer\")\"\"\")[1:])\n",
    "        ro.r(str(\"\"\"cmat <- read.table(\"*\"\"\")[:-1] + self.labels + str(\"\"\"*\")\"\"\")[1:])\n",
    "        ro.r(\"cmat$V2 <- factor(cmat$V1)\")\n",
    "\n",
    "    def fit(self, return_fc=False):\n",
    "        # computing data mask\n",
    "        set_a = np.where(self.c_train == self.cluster[0])[0]\n",
    "        subset_a = np.random.choice(set_a, self.A)\n",
    "        set_b = np.where(self.c_train == self.cluster[1])[0]\n",
    "        subset_b = np.random.choice(set_b, self.B)\n",
    "\n",
    "        stochastic_set = np.hstack((subset_a, subset_b))\n",
    "\n",
    "        # Mask 1D True False\n",
    "        f = np.array([a in stochastic_set for a in np.arange(self.X_train.shape[0])])\n",
    "\n",
    "        nr, nc = f[:, np.newaxis].shape\n",
    "        f_r = ro.r.matrix(f[:, np.newaxis], nrow=nr, ncol=nc)\n",
    "        ro.r.assign(\"f_\", f_r)\n",
    "        ro.r(\"f <- as.integer(rownames(cmat[f_,]))\")\n",
    "\n",
    "        ro.r(\"local_fmat <- log2(fmat[f, ] + 1)\")\n",
    "        ro.r(\"local_cmat <- cmat[f, ]\")\n",
    "        ro.r(\"local_cmat$V3 <- factor(local_cmat$V1)\")\n",
    "\n",
    "        ro.r(\"sca <- FromMatrix(t(data.frame(local_fmat)), data.frame(local_cmat$V3))\")\n",
    "        ro.r(\"zlmCond <- zlm(~local_cmat.V3, sca)\")\n",
    "        ro.r(\"\"\"summaryCond <- summary(zlmCond, doLRT='local_cmat.V34')\"\"\")\n",
    "        ro.r(\"summaryDt <- summaryCond$datatable\")\n",
    "        ro.r(\"\"\"fcHurdle <- merge(\n",
    "                summaryDt[contrast=='local_cmat.V34' & component=='H',.(primerid, `Pr(>Chisq)`)],\n",
    "                    #hurdle P values\n",
    "                summaryDt[contrast=='local_cmat.V34' & component=='logFC', .(primerid, coef, ci.hi, ci.lo)],\n",
    "                by='primerid') #logFC coefficients\"\"\")\n",
    "        # data = pd.DataFrame([ro.r(\"fcHurdle$primerid\"), ro.r(\"\"\"fcHurdle$'Pr(>Chisq)'\"\"\"), ro.r(\"fcHurdle$coef\")]).T\n",
    "        # data.columns = [\"gene_index\", \"p_value\", \"coeff\"]\n",
    "        # # data[\"gene_index\"] = data[\"gene_index\"].apply(lambda x: int(str(x)[1:]))\n",
    "        # data.sort_values(\"gene_index\", inplace=True)\n",
    "\n",
    "        index = [int(elem[1:]) for elem in list(ro.r(\"fcHurdle$primerid\"))]\n",
    "        p_value = list(ro.r(\"\"\"fcHurdle$'Pr(>Chisq)'\"\"\"))\n",
    "        coeff = list(ro.r(\"fcHurdle$coef\"))\n",
    "        data = pd.DataFrame(dict(pval=p_value, lfc=coeff), index=index).sort_index()\n",
    "        return data\n",
    "\n",
    "\n",
    "all_nature = False\n",
    "\n",
    "lfcs_mast = np.zeros((1, N_PICKS, n_genes))\n",
    "var_lfcs_mast = np.zeros((1, N_PICKS, n_genes))\n",
    "pvals_mast = np.zeros((1, N_PICKS, n_genes))\n",
    "for (size_ix, size) in enumerate(tqdm([SIZE])):\n",
    "    for exp in range(N_PICKS):\n",
    "        if all_nature:\n",
    "            mast_inference = NMASTcpm(\n",
    "                A=size,\n",
    "                B=size,\n",
    "                data=data_all_path,\n",
    "                labels=labels_all_path,\n",
    "                normalized_means=normalized_means,\n",
    "                delta=DELTA,\n",
    "                cluster=(0, 4),\n",
    "                path_to_scripts=PATH_TO_SCRIPTS,\n",
    "            )\n",
    "            res_df = mast_inference.fit()\n",
    "            print(res_df.info())\n",
    "            var_lfcs_mast[size_ix, exp, :] = res_df[\"varLogFC\"].values\n",
    "            lfcs_mast[size_ix, exp, :] = res_df[\"logFC\"].values\n",
    "\n",
    "        else:\n",
    "            mast_inference = MAST(\n",
    "                A=size,\n",
    "                B=size,\n",
    "                data=data_all_path,\n",
    "                labels=labels_all_path,\n",
    "                cluster=(0, 4),\n",
    "            )\n",
    "            res_df = mast_inference.fit(return_fc=True)\n",
    "            lfcs_mast[size_ix, exp, :] = res_df[\"lfc\"].values\n",
    "        pvals_mast[size_ix, exp, :] = res_df[\"pval\"].values\n",
    "mast_res = dict(\n",
    "    lfc=lfcs_mast.squeeze(), pval=pvals_mast.squeeze(), var_lfc=var_lfcs_mast\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load(filepath, my_mdl_class, my_mdl_params, my_train_params, my_train_fn_params):\n",
    "    if os.path.exists(filepath):\n",
    "        tup = load_pickle(filepath)\n",
    "    else:\n",
    "        tup = train_model(\n",
    "            mdl_class=my_mdl_class,\n",
    "            dataset=dataset,\n",
    "            mdl_params=my_mdl_params,\n",
    "            train_params=my_train_params,\n",
    "            train_fn_params=my_train_fn_params,\n",
    "        )\n",
    "        save_pickle(tup, filepath)\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    mdl_iaf, trainer_iaf = train_or_load(\n",
    "        os.path.join(DIR_PATH, \"iaf_mdl_{}final1.pickle\".format(i)),\n",
    "        IAVAE,\n",
    "        mdl_params[\"iaf\"],\n",
    "        train_params[\"base\"],\n",
    "        train_fn_params[\"base\"],\n",
    "    )\n",
    "\n",
    "    mdl_mf, trainer_mf = train_or_load(\n",
    "        os.path.join(DIR_PATH, \"mf_mdl_{}final1.pickle\".format(i)),\n",
    "        VAE,\n",
    "        mdl_params[\"mf\"],\n",
    "        train_params[\"base\"],\n",
    "        train_fn_params[\"base\"],\n",
    "    )\n",
    "\n",
    "mdl_iaf.cuda()\n",
    "mdl_mf.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microarray systematic comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions[\"mast\"][\"lfc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_gt = - microarray_info.BDC_logFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.scatter(lfcs_gt, -other_predictions[\"mast\"][\"lfc\"][0], label=\"mast\")\n",
    "plt.scatter(lfcs_gt, other_predictions[\"deseq2\"][\"lfc\"][0], label=\"deseq2\")\n",
    "plt.scatter(lfcs_gt, other_predictions[\"edger\"][\"lfc\"][0], label=\"edger\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions[\"mast\"][\"lfc\"][np.isnan(other_predictions[\"mast\"][\"lfc\"])] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def get_r2(preds, gt):\n",
    "#     y = other_predictions[\"deseq2\"][\"lfc\"][0]\n",
    "#     X = lfcs_gt\n",
    "#     X = sm.add_constant(preds)\n",
    "    model = sm.OLS(gt, preds).fit()\n",
    "    return model.rsquared\n",
    "\n",
    "\n",
    "r2_mast = np.array([get_r2(-pred, lfcs_gt) for pred in other_predictions[\"mast\"][\"lfc\"]])\n",
    "r2_deseq2 = np.array([get_r2(pred, lfcs_gt) for pred in other_predictions[\"deseq2\"][\"lfc\"]])\n",
    "r2_edger = np.array([get_r2(pred, lfcs_gt) for pred in other_predictions[\"edger\"][\"lfc\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_mast.mean())\n",
    "print(r2_deseq2.mean())\n",
    "print(r2_edger.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampled_posterior(post, indices):\n",
    "    post.data_loader.sampler.indices = indices\n",
    "    return post\n",
    "\n",
    "def compute_lfc(my_trainer, my_idx_a, my_idx_b, n_samples=1000, importance_sampling=False):\n",
    "    post_a = subsampled_posterior(my_trainer.train_set, my_idx_a)\n",
    "    outputs_a = post_a.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_a, weights_a = outputs_a[\"scale\"], outputs_a[\"log_probas\"]\n",
    "    scales_a = scales_a.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    post_b = subsampled_posterior(my_trainer.train_set, my_idx_b)\n",
    "    outputs_b = post_b.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_b, weights_b = outputs_b[\"scale\"], outputs_b[\"log_probas\"]\n",
    "    scales_b = scales_b.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    if importance_sampling:\n",
    "        weights_a = softmax(weights_a.reshape((-1)))\n",
    "        weights_b = softmax(weights_b.reshape((-1)))\n",
    "    else:\n",
    "        weights_a = None\n",
    "        weights_b = None\n",
    "    scales_a, scales_b = demultiply(\n",
    "        arr1=scales_a, arr2=scales_b, factor=3, weights_a=weights_a, weights_b=weights_b\n",
    "    )\n",
    "\n",
    "    lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "    return lfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# means_mf = []\n",
    "# means_iaf = []\n",
    "# medians_mf = []\n",
    "# medians_iaf = []\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    print(i)\n",
    "    idx_a = np.where(y_all==0)[0]\n",
    "    idx_b = np.where(y_all==4)[0]\n",
    "    idx_a = np.random.choice(idx_a, 100)\n",
    "    idx_b = np.random.choice(idx_b, 100)\n",
    "    \n",
    "    mdl_iaf, trainer_iaf = train_or_load(\n",
    "        os.path.join(DIR_PATH, \"iaf_mdl_{}final1.pickle\".format(i)),\n",
    "        IAVAE,\n",
    "        mdl_params[\"iaf\"],\n",
    "        train_params[\"base\"],\n",
    "        train_fn_params[\"base\"],\n",
    "    )\n",
    "    mdl_mf, trainer_mf = train_or_load(\n",
    "        os.path.join(DIR_PATH, \"mf_mdl_{}final1.pickle\".format(i)),\n",
    "        VAE,\n",
    "        mdl_params[\"mf\"],\n",
    "        train_params[\"base\"],\n",
    "        train_fn_params[\"base\"],\n",
    "    )\n",
    "    for _ in tqdm(range(N_PICKS)):\n",
    "        lfc_iaf = compute_lfc(trainer_iaf, idx_a, idx_b, n_samples=500)\n",
    "        lfc_mf = compute_lfc(trainer_mf, idx_a, idx_b, n_samples=500)\n",
    "\n",
    "        means_mf.append(lfc_mf.mean(0))\n",
    "        means_iaf.append(lfc_iaf.mean(0))\n",
    "        medians_mf.append(np.median(lfc_mf, 0))\n",
    "        medians_iaf.append(np.median(lfc_iaf, 0))\n",
    "\n",
    "save_pickle(means_mf, os.path.join(DIR_PATH, \"means_mf.pickle\"))\n",
    "save_pickle(means_iaf, os.path.join(DIR_PATH, \"means_iaf.pickle\"))\n",
    "save_pickle(medians_mf, os.path.join(DIR_PATH, \"medians_mf.pickle\"))\n",
    "save_pickle(medians_iaf, os.path.join(DIR_PATH, \"medians_iaf.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_mf = np.array(load_pickle(os.path.join(DIR_PATH, \"means_mf.pickle\")))\n",
    "means_iaf = np.array(load_pickle(os.path.join(DIR_PATH, \"means_iaf.pickle\")))\n",
    "medians_mf = np.array(load_pickle(os.path.join(DIR_PATH, \"medians_mf.pickle\")))\n",
    "medians_iaf = np.array(load_pickle(os.path.join(DIR_PATH, \"medians_iaf.pickle\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_mf = np.array([get_r2(pred, lfcs_gt) for pred in medians_mf])\n",
    "r2_iaf = np.array([get_r2(pred, lfcs_gt) for pred in medians_iaf])\n",
    "\n",
    "print(\"mf\", r2_mf.mean())\n",
    "print(\"iaf\", r2_iaf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.utils import has_lower_mean\n",
    "\n",
    "has_lower_mean(r2_iaf, r2_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pd.Series(\n",
    "        [\n",
    "            r2_deseq2.mean(),\n",
    "            r2_mast.mean(),\n",
    "            r2_edger.mean(),\n",
    "            r2_mf.mean(),\n",
    "            r2_iaf.mean(),\n",
    "        ],\n",
    "        index=[\"DESeq2\", \"MAST\", \"edgeR\", \"MF\", \"IAF\"],\n",
    "    )\n",
    "    .to_frame(\"RSquared\")\n",
    "    .T.round(3)\n",
    "    .applymap(lambda x: \"$ {} $\".format(x))\n",
    "    .to_latex(escape=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef(preds, gt):\n",
    "    model = sm.OLS(gt, preds).fit()\n",
    "    return model.params.x1\n",
    "\n",
    "coef_mf = np.array([get_coef(pred, lfcs_gt) for pred in medians_mf])\n",
    "coef_iaf = np.array([get_coef(pred, lfcs_gt) for pred in medians_iaf])\n",
    "coef_mast = np.array([get_coef(-pred, lfcs_gt) for pred in other_predictions[\"mast\"][\"lfc\"]])\n",
    "coef_deseq2 = np.array([get_coef(pred, lfcs_gt) for pred in other_predictions[\"deseq2\"][\"lfc\"]])\n",
    "coef_edger = np.array([get_coef(pred, lfcs_gt) for pred in other_predictions[\"edger\"][\"lfc\"]])\n",
    "\n",
    "\n",
    "\n",
    "print(coef_mf.mean())\n",
    "print(coef_iaf.mean())\n",
    "print(coef_mast.mean())\n",
    "print(coef_deseq2.mean())\n",
    "print(coef_edger.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microarray BIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampled_posterior(post, indices):\n",
    "    post.data_loader.sampler.indices = indices\n",
    "    return post\n",
    "\n",
    "def compute_lfc(my_trainer, my_idx_a, my_idx_b, n_samples=1000, importance_sampling=False):\n",
    "    post_a = subsampled_posterior(my_trainer.test_set, TEST_INDICES[my_idx_a])\n",
    "    outputs_a = post_a.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_a, weights_a = outputs_a[\"scale\"], outputs_a[\"log_probas\"]\n",
    "    scales_a = scales_a.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    post_b = subsampled_posterior(my_trainer.test_set, TEST_INDICES[my_idx_b])\n",
    "    outputs_b = post_b.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_b, weights_b = outputs_b[\"scale\"], outputs_b[\"log_probas\"]\n",
    "    scales_b = scales_b.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    if importance_sampling:\n",
    "        weights_a = softmax(weights_a.reshape((-1)))\n",
    "        weights_b = softmax(weights_b.reshape((-1)))\n",
    "    else:\n",
    "        weights_a = None\n",
    "        weights_b = None\n",
    "    scales_a, scales_b = demultiply(\n",
    "        arr1=scales_a, arr2=scales_b, factor=3, weights_a=weights_a, weights_b=weights_b\n",
    "    )\n",
    "\n",
    "    lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "    return lfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_a = np.where(y_test == 0)[0][:70]\n",
    "idx_b = np.where(y_test == 4)[0][:70]\n",
    "# idx_a = np.where(y_test == 0)[0][:70]\n",
    "# idx_b = np.where(y_test == 4)[0][:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_mf = compute_lfc(trainer_mf, idx_a, idx_b, n_samples=500)\n",
    "lfc_iaf = compute_lfc(trainer_iaf, idx_a, idx_b, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_gt = - microarray_info.BDC_logFC\n",
    "# lfcs_gt = - microarray_info.CD_logFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_genes = np.random.permutation(n_genes)[:500]\n",
    "lfc_ground_truth = lfcs_gt[random_genes]\n",
    "mean_mf = lfc_mf.mean(0)[random_genes]\n",
    "mean_iaf = lfc_iaf.mean(0)[random_genes]\n",
    "# hdis_mf = compute_hdi(lfc_mf, credible_interval=0.95)[random_genes]\n",
    "# hdis_iaf = compute_hdi(lfc_iaf, credible_interval=0.95)[random_genes]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "trace_mf = go.Scatter(\n",
    "    x=lfc_ground_truth,\n",
    "    y=mean_mf,\n",
    "    mode=\"markers\",\n",
    "#     error_y=dict(\n",
    "#         type=\"data\",\n",
    "#         symmetric=False,\n",
    "#         array=hdis_mf[:, 1] - mean_mf,\n",
    "#         arrayminus=mean_mf - hdis_mf[:, 0],\n",
    "#     ),\n",
    ")\n",
    "\n",
    "trace_iaf = go.Scatter(\n",
    "    x=lfc_ground_truth,\n",
    "    y=mean_iaf,\n",
    "    mode=\"markers\",\n",
    "#     error_y=dict(\n",
    "#         type=\"data\",\n",
    "#         symmetric=False,\n",
    "#         array=hdis_iaf[:, 1] - mean_iaf,\n",
    "#         arrayminus=mean_iaf - hdis_iaf[:, 0],\n",
    "#     ),\n",
    ")\n",
    "trace_gt = go.Scatter(\n",
    "    x=[-3, 3],\n",
    "    y=[-3, 3],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.add_traces([trace_mf, trace_iaf, trace_gt])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mast_predictions = other_predictions[\"mast\"]\n",
    "lfcs_mast = -mast_predictions[\"lfc\"]\n",
    "\n",
    "lfcs_mast[np.isnan(lfcs_mast)] = 0.0\n",
    "\n",
    "lfcs_deseq2 = other_predictions[\"deseq2\"][\"lfc\"]\n",
    "lfcs_deseq2[np.isnan(lfcs_deseq2)] = 0.0\n",
    "\n",
    "lfcs_edger = -other_predictions[\"edger\"][\"lfc\"]\n",
    "lfcs_edger[np.isnan(lfcs_edger)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = x_test[idx_a].mean(axis=0)\n",
    "h_b = x_test[idx_b].mean(axis=0)\n",
    "lfc_baseline = np.array(np.log2(h_a) - np.log2(h_b))\n",
    "lfc_baseline = np.clip(lfc_baseline, a_min=-5, a_max=5).squeeze()\n",
    "lfc_baseline[np.isnan(lfc_baseline)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "mdls = [\n",
    "    (-lfc_mf.mean(0), \"MF\"),\n",
    "    (-lfc_iaf.mean(0), \"IAF\"),\n",
    "#     (-lfcs_mast[-1, :], \"MAST\"),\n",
    "#     (-lfcs_deseq2[-1, :], \"DESeq2\"),\n",
    "#     (lfcs_edger[-1, :], \"EdgeR\"),\n",
    "#     (lfc_baseline, \"Baseline\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reg_results = dict()\n",
    "for preds, name in mdls:\n",
    "    y = preds\n",
    "    X = lfcs_gt\n",
    "#     X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    display(name, model.summary())\n",
    "    reg_results[name] = dict(rsquared=model.rsquared_adj, \n",
    "#                              coef=model.params.BDC_logFC\n",
    "                             coef=model.params.CD_logFC\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_n_genes = 110\n",
    "std_scaler = StandardScaler(with_mean=False)\n",
    "std_scaler.fit(dataset.X.astype(np.float64))\n",
    "subset_genes = np.argsort(std_scaler.var_)[::-1][:new_n_genes]\n",
    "\n",
    "# subset_genes = np.arange(n_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT : size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdt_densities(\n",
    "    filename, mdl_class, dataset, mdl_params, train_params, train_fn_params, sz=SIZE\n",
    "):\n",
    "    res = estimate_lfc_density(\n",
    "        filename=filename,\n",
    "        mdl_class=mdl_class,\n",
    "        dataset=dataset,\n",
    "        mdl_params=mdl_params,\n",
    "        train_params=train_params,\n",
    "        train_fn_params=train_fn_params,\n",
    "        sizes=[sz],\n",
    "        n_picks=N_PICKS,\n",
    "        label_a=0,\n",
    "        label_b=4,\n",
    "        n_samples=100\n",
    "    )[sz].squeeze()\n",
    "    return res\n",
    "\n",
    "\n",
    "lfcs_mf = bdt_densities(\n",
    "    filename=os.path.join(DIR_PATH, \"bdt100MF_new2.pickle\"),\n",
    "    mdl_class=VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"mf\"],\n",
    "    train_fn_params=train_fn_params[\"mf\"],\n",
    ")\n",
    "\n",
    "lfcs_ia = bdt_densities(\n",
    "    filename=os.path.join(DIR_PATH, \"bdt100IAF_new2.pickle\"),\n",
    "    mdl_class=IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"iaf\"],\n",
    "    train_params=train_params[\"iaf\"],\n",
    "    train_fn_params=train_fn_params[\"iaf\"],\n",
    ")\n",
    "\n",
    "# lfcs_iwia = estimate_lfc_density(\n",
    "#     IAVAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"iaf_k5\"],\n",
    "#     train_params=train_params[\"iaf_k5\"],\n",
    "#     train_fn_params=train_fn_params[\"iaf_k5\"],\n",
    "#     sizes=[SIZE],\n",
    "#     n_picks=1,\n",
    "#     label_a=label_a,\n",
    "#     label_b=label_b\n",
    "# )[SIZE].squeeze()\n",
    "\n",
    "# lfcs_iwmf = estimate_lfc_density(\n",
    "#     IAVAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"mf_k5\"],\n",
    "#     train_params=train_params[\"mf_k5\"],\n",
    "#     train_fn_params=train_fn_params[\"mf_k5\"],\n",
    "#     sizes=[SIZE],\n",
    "#     n_picks=1,\n",
    "#     label_a=label_a,\n",
    "#     label_b=label_b\n",
    "# )[SIZE].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_ia_100_all = lfcs_ia.reshape((-1, n_genes))\n",
    "lfcs_mf_100_all = lfcs_mf.reshape((-1, n_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "lfcs_mf_est = lfcs_ia.reshape((-1, n_genes))[:, subset_genes]\n",
    "lfcs_ia_est = lfcs_mf.reshape((-1, n_genes))[:, subset_genes]\n",
    "lfcs_mf_est_100 = lfcs_mf_est.copy()\n",
    "lfcs_ia_est_100 = lfcs_ia_est.copy()\n",
    "lfcs_gt = - microarray_info.BDC_logFC[subset_genes]\n",
    "\n",
    "print(lfcs_mf_est.shape)\n",
    "print(lfcs_ia_est.shape)\n",
    "print(lfcs_gt.shape)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Mean Field\", \"Inverse Autoregressive Flows\"),\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_plot(fig, lfcs_est_m, lfcs_est_err, row, col):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lfcs_gt,\n",
    "            y=lfcs_est_m,\n",
    "            error_y=dict(type=\"data\", array=lfcs_est_err, visible=True),\n",
    "            mode=\"markers\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "add_plot(fig, lfcs_mf_est.mean(0), 2.0*lfcs_mf_est.std(0), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-5, 5],\n",
    "        y=[-5, 5],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "add_plot(fig, lfcs_ia_est.mean(0), 2.0*lfcs_ia_est.std(0), row=1, col=2)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Ground Truth LFC\", row=1, col=1)\n",
    "# fig.update_xaxes(title_text=\"Ground Truth LFC\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Predicted LFC\", row=1, col=1)\n",
    "# fig.update_yaxes(title_text=\"Predicted LFC\", row=2, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600, width=1000, title_text=\"LFC estimation for {} sample cells B cells/DT cells\".format(SIZE)\n",
    ")\n",
    "# iplot(fig, filename=\"pbmc_microarray_lfc_with_uncertainty_{}cells_BDT\".format(SIZE), sharing=\"private\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_gt = -microarray_info.BDC_logFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_a = np.where(y_test == label_a)[0]\n",
    "where_b = np.where(y_test == label_b)[0]\n",
    "idx_a = np.random.permutation(where_a)[:100]\n",
    "idx_b = np.random.permutation(where_b)[:100]\n",
    "\n",
    "h_a = x_test[idx_a].mean(axis=0)\n",
    "h_b = x_test[idx_b].mean(axis=0)\n",
    "lfc_baseline = np.array(np.log2(h_a) - np.log2(h_b))\n",
    "lfc_baseline = np.clip(lfc_baseline, a_min=-5, a_max=5).squeeze()\n",
    "lfc_baseline[np.isnan(lfc_baseline)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mast_predictions = other_predictions[\"mast\"]\n",
    "lfcs_mast = -mast_predictions[\"lfc\"]\n",
    "stds_mast = np.sqrt(mast_predictions[\"var_lfc\"].squeeze())\n",
    "\n",
    "lfcs_mast[np.isnan(lfcs_mast)] = 0.0\n",
    "stds_mast[np.isnan(stds_mast)] = 0.0\n",
    "\n",
    "lfcs_deseq2 = other_predictions[\"deseq2\"][\"lfc\"]\n",
    "lfcs_deseq2[np.isnan(lfcs_deseq2)] = 0.0\n",
    "\n",
    "lfcs_edger = -other_predictions[\"edger\"][\"lfc\"]\n",
    "lfcs_edger[np.isnan(lfcs_edger)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "lfcs_mf_100_all\n",
    "mdls = [\n",
    "    (-lfcs_mf_100_all.mean(0), \"MF\"),\n",
    "    (-lfcs_ia_100_all.mean(0), \"IAF\"),\n",
    "    (-lfcs_mast[-1, :], \"MAST\"),\n",
    "    (-lfcs_deseq2[-1, :], \"DESeq2\"),\n",
    "    (lfcs_edger[-1, :], \"EdgeR\"),\n",
    "    (lfc_baseline, \"Baseline\"),\n",
    "]\n",
    "\n",
    "\n",
    "reg_results = dict()\n",
    "for preds, name in mdls:\n",
    "    y = preds\n",
    "    X = microarray_info.BDC_logFC\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    display(name, model.summary())\n",
    "    reg_results[name] = dict(rsquared=model.rsquared_adj, coef=model.params.BDC_logFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{0:.2f}, {1:.2f}\".format(1000.01022, 0.0100020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(title_text=\"LFC point Predictions\")\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=lfcs_gt[subset_genes],\n",
    "            y=lfcs_mf_est.mean(0),\n",
    "            #             error_y=dict(type=\"data\", array=2.0*stds_mast, visible=True),\n",
    "            mode=\"markers\",\n",
    "            name=\"MF @R^2 : {0:.2f}, Slope: {1:.2f}\".format(\n",
    "                reg_results[\"MF\"][\"rsquared\"], reg_results[\"MF\"][\"coef\"]\n",
    "            ),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=lfcs_gt[subset_genes],\n",
    "            y=lfcs_deseq2[-1, subset_genes],\n",
    "            mode=\"markers\",\n",
    "            name=\"DESeq2 @R^2 : {0:.2f}, Slope: {1:.2f}\".format(\n",
    "                reg_results[\"DESeq2\"][\"rsquared\"], reg_results[\"DESeq2\"][\"coef\"]\n",
    "            ),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=lfcs_gt[subset_genes],\n",
    "            y=lfc_baseline,\n",
    "            mode=\"markers\",\n",
    "            name=\"Baseline @R^2 : {0:.2f}, Slope: {1:.2f}\".format(\n",
    "                reg_results[\"Baseline\"][\"rsquared\"], reg_results[\"Baseline\"][\"coef\"]\n",
    "            ),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[-5, 5],\n",
    "            y=[-5, 5],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "            name=\"Reference\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#         go.Scatter(\n",
    "#             x=lfcs_gt[subset_genes],\n",
    "#             y=lfcs_edger[-1, subset_genes],\n",
    "#             mode=\"markers\",\n",
    "#             name=\"EdgeR\",\n",
    "#             text=[\n",
    "#                 \"R^2 : {0:.2f}, Slope: {1:.2f}\".format(\n",
    "#                     reg_results[\"EdgeR\"][\"rsquared\"], reg_results[\"EdgeR\"][\"coef\"]\n",
    "#                 )\n",
    "#             ],\n",
    "#         ),\n",
    "\n",
    "#         go.Scatter(\n",
    "#             x=lfcs_gt[subset_genes],\n",
    "#             y=lfcs_mast[-1, subset_genes],\n",
    "#             #             error_y=dict(type=\"data\", array=2.0*stds_mast, visible=True),\n",
    "#             mode=\"markers\",\n",
    "#             name=\"MAST\",\n",
    "#             text=[\n",
    "#                 \"R^2 : {0:.2f}, Slope: {1:.2f}\".format(\n",
    "#                     reg_results[\"MAST\"][\"rsquared\"], reg_results[\"MAST\"][\"coef\"]\n",
    "#                 )\n",
    "#             ],\n",
    "#         ),\n",
    "\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"pbmc_microarray_diags\", sharing=\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you take all genes into account, scVI clearly better predicts LFC than its competitors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voronoi Graph AKA Venn Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_probas_mf = estimate_de_proba(\n",
    "    filename=os.path.join(DIR_PATH, \"de_probas_mfNEW.npy\"),\n",
    "    mdl_class=VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"mf\"],\n",
    "    train_fn_params=train_fn_params[\"mf\"],\n",
    "    sizes=[100],\n",
    "    n_trainings=1,\n",
    "    n_picks=1,\n",
    "    label_a=label_a,\n",
    "    n_samples=300,\n",
    "    label_b=label_b\n",
    ").squeeze()\n",
    "\n",
    "de_probas_iaf = estimate_de_proba(\n",
    "    filename=os.path.join(DIR_PATH, \"de_probas_iafNEW.npy\"),\n",
    "    mdl_class=IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"iaf\"],\n",
    "    train_params=train_params[\"iaf\"],\n",
    "    train_fn_params=train_fn_params[\"iaf\"],\n",
    "    sizes=[100],\n",
    "    n_trainings=1,\n",
    "    delta=0.5,\n",
    "    n_picks=1,\n",
    "    label_a=label_a,\n",
    "    n_samples=300,\n",
    "    label_b=label_b\n",
    ").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_de_mf = predict_de_genes(de_probas_mf, desired_fdr=Q0)\n",
    "is_pred_de_iaf = predict_de_genes(de_probas_iaf, desired_fdr=Q0)\n",
    "\n",
    "is_pred_de_mf = de_probas_mf >= 0.5\n",
    "is_pred_de_iaf = de_probas_iaf >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(other_predictions[\"deseq2\"][\"pval\"].shape, other_predictions[\"deseq2\"][\"lfc\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_deseq2 = other_predictions[\"deseq2\"][\"is_de\"][0]\n",
    "is_pred_edger = other_predictions[\"edger\"][\"is_de\"][0]\n",
    "is_pred_mast = other_predictions[\"mast\"][\"is_de\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(de_probas_iaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles\n",
    "\n",
    "\n",
    "labels = np.arange(n_genes)\n",
    "de_genes_scvi = set(labels[is_pred_de_mf])\n",
    "de_genes_scvi_iaf = set(labels[is_pred_de_iaf])\n",
    "\n",
    "de_genes_deseq2 = set(labels[is_pred_deseq2])\n",
    "de_genes_edger = set(labels[is_pred_edger])\n",
    "de_genes_mast = set(labels[is_pred_mast])\n",
    "\n",
    "# venn_diagram = venn3(subsets=[de_genes_scvi, de_genes_deseq2, de_genes_mast])\n",
    "# plt.show()\n",
    "venn_diagram = venn3(\n",
    "    subsets=[de_genes_scvi_iaf, de_genes_mast, de_genes_edger],\n",
    "    set_labels=[\"IAF\", \"MAST\", \"EdgeR\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 3*[0]\n",
    "x1 = 3*[0]\n",
    "y0 = 3*[0]\n",
    "y1 = 3*[0]\n",
    "\n",
    "labels = []\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "for i in range(3):\n",
    "    r = venn_diagram.radii[i]\n",
    "    cx, cy = venn_diagram.centers[i]\n",
    "    x0[i] = cx - r\n",
    "    x1[i] = cx + r\n",
    "    y0[i] = cy - r\n",
    "    y1[i] = cy + r\n",
    "\n",
    "labels_x, labels_y, labels_text = [], [], []\n",
    "for annotation in venn_diagram.set_labels:\n",
    "    x, y = annotation.get_position()\n",
    "    text = annotation.get_text()  \n",
    "    labels_x.append(x)\n",
    "    labels_y.append(y)\n",
    "    labels_text.append(text)\n",
    "    \n",
    "ann_x, ann_y, ann_text = [], [], []\n",
    "for annotation in venn_diagram.subset_labels:\n",
    "    x, y = annotation.get_position()\n",
    "    text = annotation.get_text()  \n",
    "    ann_x.append(x)\n",
    "    ann_y.append(y)\n",
    "    ann_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "shapes = []\n",
    "for i in range(3):\n",
    "    shape = go.layout.Shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        x0=x0[i],\n",
    "        y0=y0[i],\n",
    "        x1=x1[i],\n",
    "        y1=y1[i],\n",
    "        fillcolor=colors[i],\n",
    "        line_color=colors[i],\n",
    "        opacity=0.3,\n",
    "    )\n",
    "    shapes.append(shape)\n",
    "\n",
    "\n",
    "trace_subsets = go.Scatter(x=ann_x, y=ann_y, text=ann_text, mode=\"text\", showlegend=False)\n",
    "trace_sets = go.Scatter(x=labels_x, y=labels_y, text=labels_text, mode=\"text\", showlegend=False)\n",
    "fig.add_traces([trace_subsets, trace_sets])\n",
    "fig.update_layout(\n",
    "    shapes=shapes,\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1, showgrid=False, zeroline=False),\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n",
    "iplot(fig, filename=\"pbmc_venn\", sharing=\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR and FNR (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fnr_fdr(y_true, y_pred):\n",
    "#     return dict(\n",
    "#         fnr=(y_true * (~y_pred)).sum() / (y_true).sum(),\n",
    "#         fdr=((~y_true) * (y_pred)).sum() / (y_pred).sum(),\n",
    "#     )\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(\n",
    "#     dict(\n",
    "#         MF=get_fnr_fdr(is_pred_de_mf, is_significant_de),\n",
    "#         DESeq2=get_fnr_fdr(is_pred_deseq2, is_significant_de),\n",
    "#         EdgeR=get_fnr_fdr(is_pred_edger, is_significant_de),\n",
    "#         MAST=get_fnr_fdr(is_pred_mast, is_significant_de),\n",
    "#     )\n",
    "# ).T\n",
    "\n",
    "# res_df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR Curves (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# preds_mf = de_probas_mf\n",
    "# preds_iaf = de_probas_iaf\n",
    "# preds_deseq2 = -other_predictions['deseq2']['pval'][0, :]\n",
    "# preds_edger = -other_predictions['edger']['pval'][0, :]\n",
    "# preds_mast = -other_predictions['mast']['pval'][0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.de_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_significant_de = (dataset.de_metadata[\"BDC_adj.P.Val\"] <= Q0) \n",
    "# * (dataset.de_metadata[\"BDC_logFC\"].abs() >= DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# def plot_pr(fig, preds, y_true, name):\n",
    "#     average_precision = average_precision_score(y_true, preds)\n",
    "#     preds[np.isnan(preds)] = np.min(preds[~np.isnan(preds)])\n",
    "#     precs, recs, _ = precision_recall_curve(y_true=y_true, probas_pred=preds)\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=recs,\n",
    "#             y=precs,\n",
    "#             name=name+'@AP: {0:0.2f}'.format(average_precision)\n",
    "#         )\n",
    "#     )\n",
    "#     return\n",
    "# layout = go.Layout(\n",
    "#     title='Precision Recall Curves',\n",
    "#     xaxis=dict(title='Recall'),\n",
    "#     yaxis=dict(title='Precision'),\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "# fig = go.Figure(layout=layout)\n",
    "# plot_pr(fig=fig, preds=preds_mf, y_true=is_significant_de, name='MF')\n",
    "# plot_pr(fig=fig, preds=preds_iaf, y_true=is_significant_de, name='IAF')\n",
    "# plot_pr(fig=fig, preds=preds_deseq2, y_true=is_significant_de, name='DESeq2')\n",
    "# plot_pr(fig=fig, preds=preds_edger, y_true=is_significant_de, name='EdgeR')\n",
    "# plot_pr(fig=fig, preds=preds_mast, y_true=is_significant_de, name='MAST')\n",
    "\n",
    "# iplot(fig, filename=\"pbmc_microarray_pr_curves\", sharing=\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFC VS Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_mf, trainer_mf = train_model(\n",
    "    mdl_class=VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"base\"],\n",
    "    train_fn_params=train_fn_params[\"base\"],\n",
    ")\n",
    "\n",
    "mdl_iaf, trainer_iaf = train_model(\n",
    "    mdl_class=IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"iaf\"],\n",
    "    train_params=train_params[\"base\"],\n",
    "    train_fn_params=train_fn_params[\"base\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampled_posterior(post, indices):\n",
    "    post.data_loader.sampler.indices = indices\n",
    "    return post\n",
    "\n",
    "\n",
    "def sample_random_indices(sz):\n",
    "    where_a = np.where(y_test == 0)[0]\n",
    "    where_b = np.where(y_test == 1)[0]\n",
    "    idx_a = np.random.choice(where_a, size=sz)\n",
    "    idx_b = np.random.choice(where_b, size=sz)\n",
    "    return idx_a, idx_b\n",
    "\n",
    "\n",
    "def compute_lfc(my_trainer, my_idx_a, my_idx_b, n_samples=1000, importance_sampling=False):\n",
    "    post_a = subsampled_posterior(my_trainer.test_set, TEST_INDICES[my_idx_a])\n",
    "    outputs_a = post_a.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_a, weights_a = outputs_a[\"scale\"], outputs_a[\"log_probas\"]\n",
    "    scales_a = scales_a.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    post_b = subsampled_posterior(my_trainer.test_set, TEST_INDICES[my_idx_b])\n",
    "    outputs_b = post_b.get_latents(n_samples=n_samples, other=True, device=\"cpu\")\n",
    "    scales_b, weights_b = outputs_b[\"scale\"], outputs_b[\"log_probas\"]\n",
    "    scales_b = scales_b.reshape((-1, dataset.nb_genes)).numpy()\n",
    "\n",
    "    if importance_sampling:\n",
    "        weights_a = softmax(weights_a.reshape((-1)))\n",
    "        weights_b = softmax(weights_b.reshape((-1)))\n",
    "    else:\n",
    "        weights_a = None\n",
    "        weights_b = None\n",
    "    scales_a, scales_b = demultiply(\n",
    "        arr1=scales_a, arr2=scales_b, factor=3, weights_a=weights_a, weights_b=weights_b\n",
    "    )\n",
    "\n",
    "    lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "    return lfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 50\n",
    "\n",
    "random_genes = np.random.permutation(n_genes)[:100]\n",
    "idx_a, idx_b = sample_random_indices(sz)\n",
    "lfc_mf = compute_lfc(trainer_mf, idx_a, idx_b, n_samples=500)\n",
    "lfc_iaf = compute_lfc(trainer_iaf, idx_a, idx_b, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_a_indices = np.where(dataset.labels == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mf = lfc_mf.mean(0)\n",
    "mean_iaf = lfc_iaf.mean(0)\n",
    "hdis_mf = compute_hdi(lfc_mf, credible_interval=0.95)\n",
    "hdis_iaf = compute_hdi(lfc_iaf, credible_interval=0.95)\n",
    "means = np.array(dataset.X[pop_a_indices].mean(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_de_mf = ((np.abs(lfc_mf) >= 0.5).mean(0) >= .5).astype(int)\n",
    "is_de_iaf = ((np.abs(lfc_iaf) >= 0.5).mean(0) >= .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.shape, mean_mf.shape, is_de_mf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "trace = go.Scatter(\n",
    "    x=means,\n",
    "    y=mean_mf,\n",
    "    mode=\"markers\",\n",
    "    marker_color=is_de_mf\n",
    ")\n",
    "trace_gt0 = go.Scatter(\n",
    "    x=[0, 100],\n",
    "    y=[0.5, 0.5],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"red\", width=4),\n",
    "    showlegend=False,\n",
    ")\n",
    "trace_gt1 = go.Scatter(\n",
    "    x=[0, 100],\n",
    "    y=[-0.5, -0.5],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"red\", width=4),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.add_traces([trace, trace_gt0, trace_gt1])\n",
    "fig.update_layout(xaxis_type=\"log\", xaxis_title=\"\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "trace = go.Scatter(\n",
    "    x=means,\n",
    "    y=mean_iaf,\n",
    "    mode=\"markers\",\n",
    "    marker_color=is_de_iaf\n",
    ")\n",
    "trace_gt0 = go.Scatter(\n",
    "    x=[0, 100],\n",
    "    y=[0.5, 0.5],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"red\", width=4),\n",
    "    showlegend=False,\n",
    ")\n",
    "trace_gt1 = go.Scatter(\n",
    "    x=[0, 100],\n",
    "    y=[-0.5, -0.5],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"red\", width=4),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.add_traces([trace, trace_gt0, trace_gt1])\n",
    "fig.update_layout(\n",
    "    xaxis=dict(type=\"log\", title=\"Posterior Mean\"),\n",
    "    yaxis=dict(type=\"\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "trace_mf = go.Scatter(\n",
    "    x=means[random_genes],\n",
    "    y=mean_mf[random_genes],\n",
    "    mode=\"markers\",\n",
    "    error_y=dict(\n",
    "        type=\"data\",\n",
    "        symmetric=False,\n",
    "        array=(hdis_mf[:, 1] - mean_mf)[random_genes],\n",
    "        arrayminus=(mean_mf - hdis_mf[:, 0])[random_genes],\n",
    "    ),\n",
    ")\n",
    "\n",
    "trace_iaf = go.Scatter(\n",
    "    x=means[random_genes],\n",
    "    y=mean_iaf[random_genes],\n",
    "    mode=\"markers\",\n",
    "    error_y=dict(\n",
    "        type=\"data\",\n",
    "        symmetric=False,\n",
    "        array=(hdis_iaf[:, 1] - mean_iaf)[random_genes],\n",
    "        arrayminus=(mean_iaf - hdis_iaf[:, 0])[random_genes],\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_traces([trace_mf, trace_iaf])\n",
    "fig.update_layout(xaxis_type=\"log\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predictions comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_deseq2 = other_predictions[\"deseq2\"][\"is_de\"][0]\n",
    "is_pred_edger = other_predictions[\"edger\"][\"is_de\"][0]\n",
    "is_pred_mast = other_predictions[\"mast\"][\"is_de\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_mf = de_probas_mf >= 0.5\n",
    "is_pred_iaf = de_probas_iaf >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_deseq2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = np.arange(n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn_diagram = venn3(\n",
    "    subsets=[\n",
    "        set(genes[is_pred_mast]),\n",
    "        set(genes[is_pred_deseq2]),\n",
    "        set(genes[is_pred_mf]),\n",
    "    ],\n",
    "    set_labels=[\"MAST\", \"DESeq2\", \"scVI\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "preds_mf = de_probas_mf\n",
    "preds_iaf = de_probas_iaf\n",
    "preds_deseq2 = -other_predictions['deseq2']['pval'][0, :]\n",
    "preds_edger = -other_predictions['edger']['pval'][0, :]\n",
    "preds_mast = -other_predictions['mast']['pval'][0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_mf.shape)\n",
    "print(preds_iaf.shape)\n",
    "print(preds_deseq2.shape)\n",
    "print(preds_edger.shape)\n",
    "print(preds_mast.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "\n",
    "def get_K_best(preds):\n",
    "    sorted_best =  np.argsort(-preds) # From highest to lowest scores\n",
    "    k_best = sorted_best[:K]\n",
    "    return k_best\n",
    "\n",
    "best_mf = get_K_best(preds_mf)\n",
    "best_iaf = get_K_best(preds_iaf)\n",
    "best_deseq2 = get_K_best(preds_deseq2)\n",
    "best_edger = get_K_best(preds_edger)\n",
    "best_mast = get_K_best(preds_mast)\n",
    "\n",
    "def get_aucc_couple(best1, best2, k_val=K):\n",
    "    k_vals = np.arange(1, k_val)\n",
    "    concordances = []\n",
    "    for k in k_vals:\n",
    "        common_genes = len(np.intersect1d(best1[:k], best2[:k]))\n",
    "        concordances.append(common_genes)\n",
    "    concordances = np.array(concordances)\n",
    "    aucc = concordances.sum() / (k_val*k_val/2)\n",
    "    return aucc\n",
    "\n",
    "print(np.arange(K).sum() / (K*K/2))  # Ensure normalization OK\n",
    "\n",
    "concs_mat = np.eye(5)\n",
    "methods = [\n",
    "    best_mf,\n",
    "    best_iaf,\n",
    "    best_deseq2,\n",
    "    best_edger,\n",
    "    best_mast,\n",
    "]\n",
    "labels = [\n",
    "    \"MF\",\n",
    "    \"IAF\",\n",
    "    \"DESeq2\",\n",
    "    \"EdgeR\",\n",
    "    \"MAST\",\n",
    "]\n",
    "for (idx_a, method_a) in enumerate(tqdm_notebook(methods)):\n",
    "    for (idx_b, method_b) in enumerate(methods):\n",
    "        if idx_a == idx_b:\n",
    "            continue\n",
    "        elif idx_b <= idx_a:\n",
    "            continue\n",
    "        aucc = get_aucc_couple(method_a, method_b)\n",
    "        concs_mat[idx_a, idx_b] = aucc\n",
    "        concs_mat[idx_b, idx_a] = aucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "# ff.create_dendrogram(X=concs_mat, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.rand(10, 1)\n",
    "# names = ['Jack', 'Oxana', 'John', 'Chelsea', 'Mark', 'Alice', 'Charlie', 'Rob', 'Lisa', 'Lily']\n",
    "# fig = ff.create_dendrogram(X, orientation='left', labels=names)\n",
    "# fig.update_layout(width=800, height=800)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "fig = ff.create_annotated_heatmap(concs_mat, x=labels, y=labels, colorscale='Viridis', showscale=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mf = np.argsort(-preds_mf)\n",
    "best_iaf = np.argsort(-preds_iaf)\n",
    "best_deseq2 = np.argsort(-preds_deseq2)\n",
    "best_edger = np.argsort(-preds_edger)\n",
    "best_mast = np.argsort(-preds_mast)\n",
    "\n",
    "concs_mat = np.eye(5)\n",
    "methods = [\n",
    "    best_mf,\n",
    "    best_iaf,\n",
    "    best_deseq2,\n",
    "    best_edger,\n",
    "    best_mast,\n",
    "]\n",
    "labels = [\n",
    "    \"MF\",\n",
    "    \"IAF\",\n",
    "    \"DESeq2\",\n",
    "    \"EdgeR\",\n",
    "    \"MAST\",\n",
    "]\n",
    "for (idx_a, method_a) in enumerate(tqdm_notebook(methods)):\n",
    "    for (idx_b, method_b) in enumerate(methods):\n",
    "        if idx_a == idx_b:\n",
    "            continue\n",
    "        elif idx_b <= idx_a:\n",
    "            continue\n",
    "        aucc = get_aucc_couple(method_a, method_b, k_val=n_genes)\n",
    "        concs_mat[idx_a, idx_b] = aucc\n",
    "        concs_mat[idx_b, idx_a] = aucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "fig = ff.create_annotated_heatmap(concs_mat, x=labels, y=labels, colorscale='Viridis', showscale=True)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
