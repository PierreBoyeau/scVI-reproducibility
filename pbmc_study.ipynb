{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "from chart_studio.plotly import plot, iplot\n",
    "\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scvi.dataset import PbmcDataset\n",
    "from scvi.models import VAE, IAVAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.utils import demultiply, make_dir_if_necessary, predict_de_genes, save_fig\n",
    "from scvi_utils import estimate_de_proba, estimate_lfc_density, estimate_lfc_mean\n",
    "from R_interop import all_predictions\n",
    "\n",
    "\n",
    "N_EPOCHS = 100\n",
    "DELTA = 0.5\n",
    "# SIZES = [5, 10, 20, 30, 50, 100]\n",
    "MODE = \"cloud\"\n",
    "SIZE = 100\n",
    "SIZES = [SIZE]\n",
    "N_SIZES = len(SIZES)\n",
    "\n",
    "Q0 = 5e-2\n",
    "N_TRAININGS = 5\n",
    "N_PICKS = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "PATH_TO_SCRIPTS = \"/home/ubuntu/conquer_comparison/scripts\"\n",
    "DIR_PATH = 'lfc_estimates/pbmc'\n",
    "make_dir_if_necessary(DIR_PATH)\n",
    "\n",
    "label_a = 0\n",
    "label_b = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = \"lfc_estimates/pbmc\"\n",
    "make_dir_if_necessary(DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PbmcDataset()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(\n",
    "    dataset.labels.squeeze(), return_counts=True\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(dict(counts=counts_elements, cell_types=dataset.cell_types))\n",
    "px.scatter(df, y=\"counts\", x=\"cell_types\")\n",
    "\n",
    "n_genes = dataset.nb_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microarray_info = dataset.de_metadata.set_index('ENSG')\n",
    "microarray_info = microarray_info.loc[dataset.gene_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.de_metadata.head())\n",
    "print(dataset.de_metadata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_examples = len(dataset)\n",
    "# labels = dataset.labels.squeeze()\n",
    "# interesting_indices = np.where((labels == 0) | (labels == 2))[0]\n",
    "# TEST_INDICES = np.random.permutation(interesting_indices)[:1001]\n",
    "TEST_INDICES = np.random.permutation(len(dataset))[:1500]\n",
    "\n",
    "x_test, y_test = dataset.X[TEST_INDICES, :], dataset.labels[TEST_INDICES, :].squeeze()\n",
    "data_path = os.path.join(DIR_PATH, 'data.npy')\n",
    "labels_path = os.path.join(DIR_PATH, 'labels.npy')\n",
    "\n",
    "np.save(\n",
    "    data_path,\n",
    "    np.array(x_test.todense()).squeeze().astype(int)\n",
    ")\n",
    "np.savetxt(\n",
    "    labels_path,\n",
    "    y_test.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_params = dict(\n",
    "    iaf=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    "    iaf_k5=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf_k5=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    ")\n",
    "train_params = dict(\n",
    "    iaf=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    mf=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    iaf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5),\n",
    "    mf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5)\n",
    ")\n",
    "train_fn_params = dict(\n",
    "    iaf=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    mf=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    iaf_k5=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    mf_k5=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_predictions = all_predictions(\n",
    "    n_genes=n_genes, \n",
    "    n_picks=N_PICKS, \n",
    "    sizes=SIZES, \n",
    "    data_path=data_path, \n",
    "    labels_path=labels_path,\n",
    "    path_to_scripts=PATH_TO_SCRIPTS,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b,\n",
    "    all_nature=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfcs_mf = estimate_lfc_density(\n",
    "    VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"mf\"],\n",
    "    train_fn_params=train_fn_params[\"mf\"],\n",
    "    sizes=[SIZE],\n",
    "    n_picks=1,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b\n",
    ")[SIZE].squeeze()\n",
    "\n",
    "lfcs_ia = estimate_lfc_density(\n",
    "    IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"iaf\"],\n",
    "    train_params=train_params[\"iaf\"],\n",
    "    train_fn_params=train_fn_params[\"iaf\"],\n",
    "    sizes=[SIZE],\n",
    "    n_picks=1,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b\n",
    ")[SIZE].squeeze()\n",
    "\n",
    "# lfcs_iwia = estimate_lfc_density(\n",
    "#     IAVAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"iaf_k5\"],\n",
    "#     train_params=train_params[\"iaf_k5\"],\n",
    "#     train_fn_params=train_fn_params[\"iaf_k5\"],\n",
    "#     sizes=[SIZE],\n",
    "#     n_picks=1,\n",
    "#     label_a=label_a,\n",
    "#     label_b=label_b\n",
    "# )[SIZE].squeeze()\n",
    "\n",
    "# lfcs_iwmf = estimate_lfc_density(\n",
    "#     IAVAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"mf_k5\"],\n",
    "#     train_params=train_params[\"mf_k5\"],\n",
    "#     train_fn_params=train_fn_params[\"mf_k5\"],\n",
    "#     sizes=[SIZE],\n",
    "#     n_picks=1,\n",
    "#     label_a=label_a,\n",
    "#     label_b=label_b\n",
    "# )[SIZE].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_n_genes = 500\n",
    "\n",
    "std_scaler = StandardScaler(with_mean=False)\n",
    "std_scaler.fit(dataset.X.astype(np.float64))\n",
    "subset_genes = np.argsort(std_scaler.var_)[::-1][:new_n_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lfcs_mf_est.shape)\n",
    "print(lfcs_ia_est.shape)\n",
    "print(lfcs_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "lfcs_mf_est = lfcs_ia.reshape((-1, n_genes))[:, subset_genes]\n",
    "lfcs_ia_est = lfcs_mf.reshape((-1, n_genes))[:, subset_genes]\n",
    "lfcs_gt = - microarray_info.BDC_logFC[subset_genes]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Mean Field\", \"Inverse Autoregressive Flows\"),\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_plot(fig, lfcs_est_m, lfcs_est_err, row, col):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lfcs_gt,\n",
    "            y=lfcs_est_m,\n",
    "            error_y=dict(type=\"data\", array=lfcs_est_err, visible=True),\n",
    "            mode=\"markers\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "add_plot(fig, lfcs_mf_est.mean(0), lfcs_mf_est.std(0), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "add_plot(fig, lfcs_ia_est.mean(0), lfcs_ia_est.std(0), row=1, col=2)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Ground Truth LFC\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Ground Truth LFC\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Predicted LFC\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Predicted LFC\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000, width=1000, title_text=\"LFC estimation for {} sample cells\".format(SIZE)\n",
    ")\n",
    "\n",
    "save_fig(fig, filename=\"pbmc_microarray_lfc_with_uncertainty\", do_cloud=DO_CLOUD)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# 'BDC_logFC', y='lfc_MF'\n",
    "y = microarray_info.lfc_MF\n",
    "X = microarray_info.BDC_logFC\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voronoi Graph AKA Venn Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_probas_mf = estimate_de_proba(\n",
    "    VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"mf\"],\n",
    "    train_fn_params=train_fn_params[\"mf\"],\n",
    "    sizes=[SIZE],\n",
    "    n_trainings=1,\n",
    "    n_picks=1,\n",
    ").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_de_mf = predict_de_genes(de_probas_mf, desired_fdr=Q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Usual Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
