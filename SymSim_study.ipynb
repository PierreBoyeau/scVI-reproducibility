{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "from chart_studio.plotly import plot, iplot\n",
    "\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scvi.dataset import GeneExpressionDataset\n",
    "from scvi.models import VAE, IAVAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.utils import demultiply, make_dir_if_necessary, predict_de_genes, save_fig, load_pickle, save_pickle\n",
    "from scvi_utils import estimate_de_proba, estimate_lfc_density, estimate_lfc_mean, train_model, multi_train_estimates\n",
    "from R_interop import all_predictions, all_de_predictions\n",
    "\n",
    "\n",
    "N_EPOCHS = 100\n",
    "DELTA = 0.5\n",
    "SIZES = [5, 10, 20, 30, 50, 100]\n",
    "SIZE = 100\n",
    "N_SIZES = len(SIZES)\n",
    "DO_CLOUD = True\n",
    "Q0 = 5e-2\n",
    "N_TRAININGS = 5\n",
    "N_PICKS = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "PATH_TO_SCRIPTS = \"/home/ubuntu/conquer_comparison/scripts\"\n",
    "DIR_PATH = 'lfc_estimates/symsim'\n",
    "make_dir_if_necessary(DIR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "py.sign_in(\"pierreboyeau\", \"2wvdnWZ2Qut1zD07ADVy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symsim_data_path = \"/home/ubuntu/symsim_result/DE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs_all = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.obsv.3.csv\"), index_col=0\n",
    ").T\n",
    "\n",
    "select_gene = np.where(x_obs_all.mean(0) <= 1000)[0]\n",
    "x_obs = x_obs_all.iloc[:, select_gene]\n",
    "\n",
    "batch_info = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.batchid.csv\"), index_col=0\n",
    ") - 1\n",
    "metadata = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.cell_meta.csv\"), index_col=0\n",
    ")\n",
    "true_ = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.true.csv\"), index_col=0\n",
    ").T.iloc[:, select_gene]\n",
    "lfc_info = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"med_theoreticalFC.csv\"), index_col=0\n",
    ").iloc[select_gene, :]\n",
    "\n",
    "display(\"batch_info\", batch_info.head())\n",
    "display(\"metadata\", metadata.head())\n",
    "display(\"x_obs\", x_obs.head())\n",
    "display(\"true_\", true_.head())\n",
    "display(\"lfc_info\", lfc_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(x_obs.max(0))[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(metadata, x=\"pop\", width=400, height=300).show()\n",
    "px.histogram(lfc_info, x=\"12\", width=400, height=300).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeneExpressionDataset()\n",
    "dataset.populate_from_data(\n",
    "    X=x_obs.values,\n",
    "    batch_indices=batch_info[\"x\"].values,\n",
    "    labels=metadata[\"pop\"],\n",
    "    cell_types=metadata[\"pop\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset.local_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = len(dataset)\n",
    "TEST_INDICES = np.random.np.random.permutation(n_examples)[:2000]\n",
    "\n",
    "x_test, y_test = dataset.X[TEST_INDICES, :], dataset.labels[TEST_INDICES, :].squeeze()\n",
    "data_path = os.path.join(DIR_PATH, 'data.npy')\n",
    "labels_path = os.path.join(DIR_PATH, 'labels.npy')\n",
    "\n",
    "np.save(\n",
    "    data_path,\n",
    "    x_test.squeeze().astype(int)\n",
    ")\n",
    "np.savetxt(\n",
    "    labels_path,\n",
    "    y_test.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = dataset.batch_indices.squeeze() == 1\n",
    "x_batch = dataset.X[batch_idx]\n",
    "print(x_batch)\n",
    "print(dataset.X[batch_idx].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_params = dict(\n",
    "    iaf=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    "    iaf_k5=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=10, t=4),\n",
    "    mf_k5=dict(n_hidden=128, n_layers=1, n_latent=10),\n",
    ")\n",
    "train_params = dict(\n",
    "    iaf=dict(ratio_loss=True, test_indices=TEST_INDICES, frequency=1.0),\n",
    "    mf=dict(ratio_loss=True, test_indices=TEST_INDICES, frequency=1.0),\n",
    "    iaf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5),\n",
    "    mf_k5=dict(ratio_loss=True, test_indices=TEST_INDICES, k_importance_weighted=5)\n",
    ")\n",
    "train_fn_params = dict(\n",
    "    iaf=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    mf=dict(n_epochs=N_EPOCHS, lr=1e-2),\n",
    "    iaf_k5=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    mf_k5=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that everything ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf, mf_trainer = train_model(\n",
    "#     mdl_class=VAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"mf\"],\n",
    "#     train_params=train_params[\"mf\"],\n",
    "#     train_fn_params=train_fn_params[\"mf\"],\n",
    "# )\n",
    "# iaf, iaf_trainer = train_model(\n",
    "#     mdl_class=IAVAE,\n",
    "#     dataset=dataset,\n",
    "#     mdl_params=mdl_params[\"iaf\"],\n",
    "#     train_params=train_params[\"iaf\"],\n",
    "#     train_fn_params=train_fn_params[\"iaf\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(mf_trainer.train_losses[5:], label=\"mf\")\n",
    "# plt.plot(iaf_trainer.train_losses[5:], label=\"iaf\")\n",
    "# plt.legend()\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_mf, labels_mf = mf_trainer.train_set.get_latents()\n",
    "# z_iaf, labels_iaf = iaf_trainer.train_set.get_latents()\n",
    "\n",
    "# z_mf = z_mf.cpu()\n",
    "# z_iaf = z_iaf.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# idx = np.random.permutation(len(z_mf))[:1000]\n",
    "# z_tsne = TSNE().fit_transform(z_mf[idx, :])\n",
    "# labels_tsne = labels_mf[idx, :].cpu().squeeze()\n",
    "\n",
    "# trace = go.Scatter(\n",
    "#     x=z_tsne[:, 0],\n",
    "#     y=z_tsne[:, 1],\n",
    "#     marker_color=labels_tsne,\n",
    "#     mode=\"markers\",\n",
    "#     marker_showscale=True,\n",
    "# )\n",
    "# fig = go.Figure([trace])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(dataset.labels.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_tsne = TSNE().fit_transform(z_iaf[idx, :])\n",
    "# labels_tsne = labels_iaf[idx, :].cpu().squeeze()\n",
    "\n",
    "# trace = go.Scatter(\n",
    "#     x=z_tsne[:, 0],\n",
    "#     y=z_tsne[:, 1],\n",
    "#     marker_color=labels_tsne,\n",
    "#     mode=\"markers\",\n",
    "#     marker_showscale=True,\n",
    "# )\n",
    "# fig = go.Figure([trace])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_iaf, labels_iaf, scales_iaf = iaf_trainer.test_set.get_latents(n_samples=100, other='scales', device=\"cpu\")\n",
    "\n",
    "\n",
    "# from scvi.utils import plot_identity\n",
    "\n",
    "# where_a = np.where(labels_iaf == 0)[0][:200]\n",
    "# where_b = np.where(labels_iaf == 1)[0][:200]\n",
    "\n",
    "\n",
    "# scales_a = scales_iaf[:, where_a, :]\n",
    "# scales_b = scales_iaf[:, where_b, :]\n",
    "\n",
    "# lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "# lfc = lfc.mean((0, 1))\n",
    "\n",
    "# plt.scatter(x=lfc, y=lfc_gt)\n",
    "# plot_identity()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not same indices (in R, 0 corresponds to 1)\n",
    "label_a = 0\n",
    "label_b = 1\n",
    "n_genes = dataset.nb_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lfc_info[\"12\"].abs() >= DELTA).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_significant_de = (lfc_info[\"12\"].abs() >= DELTA).values\n",
    "lfc_gt = lfc_info[\"12\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute competitors scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_predictions = all_predictions(\n",
    "    filename=os.path.join(DIR_PATH, \"other_predictions.pickle\"),\n",
    "    n_genes=n_genes, \n",
    "    n_picks=N_PICKS, \n",
    "    sizes=SIZES, \n",
    "    data_path=data_path, \n",
    "    labels_path=labels_path,\n",
    "    path_to_scripts=PATH_TO_SCRIPTS,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b\n",
    ")\n",
    "\n",
    "other_predictions = all_de_predictions(\n",
    "    other_predictions, significance_level=Q0, delta=DELTA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=os.path.join(DIR_PATH, \"other_predictions.pickle\")\n",
    "n_genes=n_genes \n",
    "n_picks=N_PICKS \n",
    "sizes=SIZES \n",
    "data_path=data_path \n",
    "labels_path=labels_path\n",
    "path_to_scripts=PATH_TO_SCRIPTS\n",
    "label_a=label_a\n",
    "label_b=label_b\n",
    "all_nature = False\n",
    "lfc_threshold = 0.5\n",
    "\n",
    "from R_interop import NDESeq2, NEdgeRLTRT, NMASTcpm, MAST\n",
    "from tqdm import tqdm\n",
    "\n",
    "# n_sizes = len(sizes)\n",
    "\n",
    "# # DESeq2\n",
    "# lfcs_deseq2 = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# pvals_deseq2 = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# for (size_ix, size) in enumerate(tqdm(sizes)):\n",
    "#     for exp in range(n_picks):\n",
    "#         deseq_inference = NDESeq2(\n",
    "#             A=size,\n",
    "#             B=size,\n",
    "#             data=data_path,\n",
    "#             labels=labels_path,\n",
    "#             cluster=(label_a, label_b),\n",
    "#             path_to_scripts=path_to_scripts,\n",
    "#             lfc_threshold=lfc_threshold,\n",
    "#         )\n",
    "#         res_df = deseq_inference.fit()\n",
    "#         lfcs_deseq2[size_ix, exp, :] = res_df[\"lfc\"].values\n",
    "#         pvals_deseq2[size_ix, exp, :] = res_df[\"padj\"].values\n",
    "# deseq_res = dict(lfc=lfcs_deseq2.squeeze(), pval=pvals_deseq2.squeeze())\n",
    "\n",
    "# # EdgeR\n",
    "# lfcs_edge_r = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# pvals_edge_r = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# for (size_ix, size) in enumerate(tqdm(sizes)):\n",
    "#     for exp in range(n_picks):\n",
    "#         deseq_inference = NEdgeRLTRT(\n",
    "#             A=size,\n",
    "#             B=size,\n",
    "#             data=data_path,\n",
    "#             labels=labels_path,\n",
    "#             cluster=(label_a, label_b),\n",
    "#             path_to_scripts=path_to_scripts,\n",
    "#         )\n",
    "#         res_df = deseq_inference.fit()\n",
    "#         lfcs_edge_r[size_ix, exp, :] = res_df[\"lfc\"].values\n",
    "#         pvals_edge_r[size_ix, exp, :] = res_df[\"padj\"].values\n",
    "# edger_res = dict(lfc=lfcs_edge_r.squeeze(), pval=pvals_edge_r.squeeze())\n",
    "\n",
    "# # MAST\n",
    "# lfcs_mast = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# var_lfcs_mast = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# pvals_mast = np.zeros((n_sizes, n_picks, n_genes))\n",
    "# for (size_ix, size) in enumerate(tqdm(sizes)):\n",
    "#     for exp in range(n_picks):\n",
    "#         if all_nature:\n",
    "#             mast_inference = NMASTcpm(\n",
    "#                 A=size,\n",
    "#                 B=size,\n",
    "#                 data=data_path,\n",
    "#                 labels=labels_path,\n",
    "#                 cluster=(label_a, label_b),\n",
    "#                 path_to_scripts=path_to_scripts,\n",
    "#             )\n",
    "#             res_df = mast_inference.fit()\n",
    "#             print(res_df.info())\n",
    "#             var_lfcs_mast[size_ix, exp, :] = res_df[\"varLogFC\"].values\n",
    "#             lfcs_mast[size_ix, exp, :] = res_df[\"logFC\"].values\n",
    "\n",
    "#         else:\n",
    "#             mast_inference = MAST(\n",
    "#                 A=size,\n",
    "#                 B=size,\n",
    "#                 data=data_path,\n",
    "#                 labels=labels_path,\n",
    "#                 cluster=(label_a, label_b),\n",
    "#             )\n",
    "#             res_df = mast_inference.fit(return_fc=True)\n",
    "#             lfcs_mast[size_ix, exp, :] = res_df[\"lfc\"].values\n",
    "#         pvals_mast[size_ix, exp, :] = res_df[\"pval\"].values\n",
    "# mast_res = dict(\n",
    "#     lfc=lfcs_mast.squeeze(), pval=pvals_mast.squeeze(), var_lfc=var_lfcs_mast\n",
    "# )\n",
    "\n",
    "# results = dict(deseq2=deseq_res, edger=edger_res, mast=mast_res)\n",
    "# save_pickle(data=results, filename=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (size_ix, size) in enumerate(tqdm(sizes)):\n",
    "#     for exp in range(n_picks):\n",
    "#         deseq_inference = NDESeq2(\n",
    "#             A=size,\n",
    "#             B=size,\n",
    "#             data=data_path,\n",
    "#             labels=labels_path,\n",
    "#             cluster=(label_a, label_b),\n",
    "#             path_to_scripts=path_to_scripts,\n",
    "#             lfc_threshold=lfc_threshold,\n",
    "#         )\n",
    "#         res_df = deseq_inference.fit()\n",
    "#         lfcs_deseq2[size_ix, exp, :] = res_df[\"lfc\"].values\n",
    "#         pvals_deseq2[size_ix, exp, :] = res_df[\"padj\"].values\n",
    "# deseq_res = dict(lfc=lfcs_deseq2.squeeze(), pval=pvals_deseq2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_predictions = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mf = multi_train_estimates(\n",
    "    filename=os.path.join(DIR_PATH, \"res_mf.pickle\"),\n",
    "    mdl_class=VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"mf\"],\n",
    "    train_params=train_params[\"mf\"],\n",
    "    train_fn_params=train_fn_params[\"mf\"],\n",
    "    sizes=SIZES,\n",
    "    n_trainings=N_TRAININGS,\n",
    "    n_picks=N_PICKS,\n",
    "    label_a=label_a,\n",
    "    label_b=label_b\n",
    ").assign(algorithm=\"MF\")\n",
    "\n",
    "res_iaf = multi_train_estimates(\n",
    "    filename=os.path.join(DIR_PATH, \"res_ia.pickle\"),\n",
    "    mdl_class=IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=mdl_params[\"iaf\"],\n",
    "    train_params=train_params[\"iaf\"],\n",
    "    train_fn_params=train_fn_params[\"iaf\"],\n",
    "    sizes=SIZES,\n",
    "    n_trainings=N_TRAININGS,\n",
    "    n_picks=N_PICKS,\n",
    "    label_a=label_a,\n",
    ").assign(algorithm=\"IAF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR / Power Control and PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    mdl_class, dataset, mdl_params: dict, train_params: dict, train_fn_params: dict\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    :param mdl_class: Class of algorithm\n",
    "    :param dataset: Dataset\n",
    "    :param mdl_params:\n",
    "    :param train_params:\n",
    "    :param train_fn_params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    my_vae = mdl_class(dataset.nb_genes, n_batch=dataset.n_batches, **mdl_params)\n",
    "    my_trainer = UnsupervisedTrainer(my_vae, dataset, **train_params)\n",
    "    print(my_trainer.test_set.data_loader.sampler.indices)\n",
    "    my_trainer.train(**train_fn_params)\n",
    "    print(my_trainer.train_losses)\n",
    "    return my_vae, my_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FDR and TPR Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_fnr(my_df):\n",
    "    my_df = my_df.sort_values(\"gene\")\n",
    "    assert len(my_df) == n_genes\n",
    "    is_pred_de = predict_de_genes(my_df.de_proba.values, desired_fdr=Q0)\n",
    "    true_fdr = ((1.0 - is_significant_de) * is_pred_de).sum() / is_pred_de.sum()\n",
    "    n_positives = is_significant_de.sum()\n",
    "    true_fnr = (is_significant_de * (1.0 - is_pred_de)).sum() / n_positives\n",
    "    return pd.Series(dict(fdr=true_fdr, fnr=true_fnr))\n",
    "\n",
    "\n",
    "fdr_fnr_mf = (\n",
    "    res_mf.groupby([\"experiment\", \"training\", \"sample_size\"])\n",
    "    .apply(fdr_fnr)\n",
    "    .reset_index()\n",
    "    .assign(algorithm=\"MF\")\n",
    ")\n",
    "fdr_fnr_iaf = (\n",
    "    res_iaf.groupby([\"experiment\", \"training\", \"sample_size\"])\n",
    "    .apply(fdr_fnr)\n",
    "    .reset_index()\n",
    "    .assign(algorithm=\"IAF\")\n",
    ")\n",
    "\n",
    "df = pd.concat([fdr_fnr_mf, fdr_fnr_iaf], ignore_index=True)\n",
    "\n",
    "\n",
    "fig = px.box(\n",
    "    df,\n",
    "    x=\"sample_size\",\n",
    "    y=\"fdr\",\n",
    "    color=\"algorithm\",\n",
    "    title=\"Control on False Discovery Rate\",\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"powsimr_fdr_control\")\n",
    "\n",
    "fig = px.box(\n",
    "    df,\n",
    "    x=\"sample_size\",\n",
    "    y=\"fnr\",\n",
    "    color=\"algorithm\",\n",
    "    title=\"Control on False Negative Rate\",\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"powsimr_power_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['deseq2', 'edger', 'mast']\n",
    "\n",
    "def get_fdr_fnr(y_pred, y_true):\n",
    "    \"\"\"\n",
    "        y_pred: (n_sz, n_picks, n_genes) bool predictions\n",
    "        y_true: (n_genes) gt vals\n",
    "    \"\"\"\n",
    "    n_sz, n_picks, _ = y_pred.shape\n",
    "    fnrs = np.zeros((n_sz, n_picks))\n",
    "    fdrs = np.zeros((n_sz, n_picks))\n",
    "    for sz in range(n_sz):\n",
    "        for pick in range(n_picks):\n",
    "            y_pred_it = y_pred[sz, pick, :]\n",
    "            fnr = ((~y_true) * y_pred_it).sum() / y_pred_it.sum()\n",
    "            fdr = (y_true * (~y_pred_it)).sum() / y_true.sum()\n",
    "            fnrs[sz, pick] = fnr\n",
    "            fdrs[sz, pick] = fdr\n",
    "    fnrs[np.isnan(fnrs)] = 0.0\n",
    "    return dict(fnr=fnrs, fdr=fdrs)\n",
    "\n",
    "print(other_predictions[\"mast\"]['pval'].shape)\n",
    "print(other_predictions[\"deseq2\"]['pval'].shape)\n",
    "print(other_predictions[\"edger\"]['pval'].shape)\n",
    "\n",
    "is_de_mast = other_predictions[\"mast\"][\"is_de\"]\n",
    "is_de_deseq2 = other_predictions[\"deseq2\"][\"is_de\"]\n",
    "is_de_edger = other_predictions[\"edger\"][\"is_de\"]\n",
    "\n",
    "res_mast = get_fdr_fnr(is_de_mast, y_true=is_significant_de)\n",
    "res_deseq2 = get_fdr_fnr(is_de_deseq2, y_true=is_significant_de)\n",
    "res_edger = get_fdr_fnr(is_de_edger, y_true=is_significant_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains_res = all_fdrs.mean(axis=1)\n",
    "# print(trains_res.mean(), trains_res.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_preds_1d = y_preds.reshape((-1, dataset.nb_genes))\n",
    "# n_exps = len(y_preds_1d)\n",
    "# confs = np.zeros((n_exps, 2, 2))\n",
    "# for i in range(n_exps):\n",
    "#     confs[i, :, :] = confusion_matrix(is_significant_de, y_preds_1d[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(is_significant_de, y_preds_1d[0, :])\n",
    "\n",
    "# confs_mean = confs.mean(0)\n",
    "# confs_mean\n",
    "\n",
    "# fig = ff.create_annotated_heatmap(\n",
    "#     z=confs_mean, x=[\"Pred Negative\", \"Pred Positive\"], y=[\"GT Negative\", \"GT Positive\"]\n",
    "# )\n",
    "# fig.update({\"layout\": dict(title=\"Confusion Matrix\")})\n",
    "\n",
    "# py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_training = 1\n",
    "\n",
    "preds_md = res_mf.loc[\n",
    "    lambda x: (x.experiment == 0) & (x.training == selected_training) & (x.sample_size == 100)\n",
    "].sort_values(\"gene\")[\"de_proba\"]\n",
    "\n",
    "preds_iaf = res_iaf.loc[\n",
    "    lambda x: (x.experiment == 0) & (x.training == selected_training) & (x.sample_size == 100)\n",
    "].sort_values(\"gene\")[\"de_proba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "preds_deseq2 = 1.0 - other_predictions['deseq2']['pval'][-1, 0, :]\n",
    "preds_edger = 1.0 - other_predictions['edger']['pval'][-1, 0, :]\n",
    "preds_mast = 1.0 - other_predictions['mast']['pval'][-1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(preds_md).mean())\n",
    "print(np.isnan(preds_iaf).mean())\n",
    "print(np.isnan(preds_deseq2).mean())\n",
    "print(np.isnan(preds_deseq2).mean())\n",
    "print(np.isnan(preds_edger).mean())\n",
    "print(np.isnan(preds_mast).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_deseq2[np.isnan(preds_deseq2)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_pr(fig, preds, y_true, name):\n",
    "    average_precision = average_precision_score(y_true, preds)\n",
    "    preds[np.isnan(preds)] = np.min(preds[~np.isnan(preds)])\n",
    "    precs, recs, _ = precision_recall_curve(y_true=y_true, probas_pred=preds)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=recs,\n",
    "            y=precs,\n",
    "            name=name+'@AP: {0:0.2f}'.format(average_precision)\n",
    "        )\n",
    "    )\n",
    "    return\n",
    "layout = go.Layout(\n",
    "    title='Precision Recall Curves',\n",
    "    xaxis=dict(title='Recall'),\n",
    "    yaxis=dict(title='Precision'),\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig = go.Figure(layout=layout)\n",
    "plot_pr(fig=fig, preds=preds_md, y_true=is_significant_de, name='MF')\n",
    "plot_pr(fig=fig, preds=preds_iaf, y_true=is_significant_de, name='IAF')\n",
    "plot_pr(fig=fig, preds=preds_deseq2, y_true=is_significant_de, name='DESeq2')\n",
    "plot_pr(fig=fig, preds=preds_edger, y_true=is_significant_de, name='EdgeR')\n",
    "plot_pr(fig=fig, preds=preds_mast, y_true=is_significant_de, name='MAST')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene ranking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_md.shape)\n",
    "print(preds_iaf.shape)\n",
    "print(preds_deseq2.shape)\n",
    "print(preds_edger.shape)\n",
    "print(preds_mast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ranks_md = np.argsort(-preds_md)\n",
    "gene_ranks_iaf = np.argsort(-preds_iaf)\n",
    "gene_ranks_deseq2 = np.argsort(-preds_deseq2)\n",
    "gene_ranks_edger = np.argsort(-preds_edger)\n",
    "gene_ranks_mast = np.argsort(-preds_mast)\n",
    "\n",
    "gt_ranks = np.argsort(-np.abs(lfc_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# rhos_md = spearmanr(gene_ranks_md, gt_ranks)\n",
    "# rhos_iaf = spearmanr(gene_ranks_iaf, gt_ranks)\n",
    "# rhos_deseq2 = spearmanr(gene_ranks_deseq2, gt_ranks)\n",
    "# rhos_edger = spearmanr(gene_ranks_edger, gt_ranks)\n",
    "# rhos_mast = spearmanr(gene_ranks_mast, gt_ranks)\n",
    "\n",
    "rhos_md = spearmanr(preds_md, lfc_gt)\n",
    "rhos_iaf = spearmanr(preds_iaf, lfc_gt)\n",
    "rhos_deseq2 = spearmanr(preds_deseq2, lfc_gt)\n",
    "rhos_edger = spearmanr(preds_edger, lfc_gt)\n",
    "rhos_mast = spearmanr(preds_mast, lfc_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rhos_md)\n",
    "print(rhos_iaf)\n",
    "print(rhos_deseq2)\n",
    "print(rhos_edger)\n",
    "print(rhos_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volcano Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    layout=go.Layout(\n",
    "        yaxis=dict(title=\"Estimated probabily of DE\"),\n",
    "        xaxis=dict(title=\"Ground-Truth LFC\"),\n",
    "    )\n",
    ")\n",
    "fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(x=lfc_gt, y=np.log10(preds_md), mode=\"markers\"),\n",
    "        go.Scatter(x=lfc_gt, y=np.log10(preds_iaf), mode=\"markers\"),\n",
    "#         go.Scatter(x=lfc_gt, y=np.log10(preds_mast), mode=\"markers\"),\n",
    "#         go.Scatter(x=lfc_gt, y=np.log10(preds_edger), mode=\"markers\"),\n",
    "        go.Scatter(\n",
    "            x=[-0.5, -0.5], y=[-6, 0.0], mode=\"lines\", line=dict(color=\"black\", width=2)\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[0.5, 0.5], y=[-6, 0.0], mode=\"lines\", line=dict(color=\"black\", width=2)\n",
    "        ),\n",
    "        #         go.Scatter(\n",
    "        #             x=[alpha, alpha], y=[-6, 0.0], mode=\"lines\", line=dict(color=\"black\", width=2)\n",
    "        #         ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "iplot(fig, filename=\"symsim_volcano\", sharing=\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonal Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subsample_genes = np.sort(np.random.permutation(n_genes)[:150])\n",
    "\n",
    "lfcs_mf = (\n",
    "    res_mf\n",
    "    .loc[\n",
    "        lambda x: (x.experiment == 0)\n",
    "        & (x.training == selected_training)\n",
    "        & (x.sample_size == 100)\n",
    "        & (x.gene.isin(subsample_genes))\n",
    "    ]\n",
    "    .sort_values(\"gene\")\n",
    "    [[\"lfc_mean\", \"hdi64_low\", \"hdi64_high\", \"algorithm\"]]\n",
    "    .assign(\n",
    "        err_minus=lambda x: x.lfc_mean - x.hdi64_low,\n",
    "        err_pos=lambda x: x.hdi64_high - x.lfc_mean,\n",
    "        lfc_gt=lfc_gt[subsample_genes]\n",
    "    )\n",
    ")\n",
    "\n",
    "lfcs_ia = (\n",
    "    res_iaf\n",
    "    .loc[\n",
    "        lambda x: (x.experiment == 0)\n",
    "        & (x.training == selected_training)\n",
    "        & (x.sample_size == 100)\n",
    "        & (x.gene.isin(subsample_genes))\n",
    "    ]\n",
    "    .sort_values(\"gene\")\n",
    "    [[\"lfc_mean\", \"hdi64_low\", \"hdi64_high\", \"algorithm\"]]\n",
    "    .assign(\n",
    "        err_minus=lambda x: x.lfc_mean - x.hdi64_low,\n",
    "        err_pos=lambda x: x.hdi64_high - x.lfc_mean,\n",
    "        lfc_gt=lfc_gt[subsample_genes]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "all_lfcs = pd.concat([lfcs_mf, lfcs_ia], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    lfcs_mf,\n",
    "    x=\"lfc_gt\",\n",
    "    y=\"lfc_mean\",\n",
    "    error_y=\"err_pos\",\n",
    "    error_y_minus=\"err_minus\",\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    lfcs_ia,\n",
    "    x=\"lfc_gt\",\n",
    "    y=\"lfc_mean\",\n",
    "    error_y=\"err_pos\",\n",
    "    error_y_minus=\"err_minus\",\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    all_lfcs,\n",
    "    x=\"lfc_gt\",\n",
    "    y=\"lfc_mean\",\n",
    "    color=\"algorithm\",\n",
    "    error_y=\"err_pos\",\n",
    "    error_y_minus=\"err_minus\",\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of LFC errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_l2_err(diff):\n",
    "    res = 0.5 * (diff ** 2) ** (0.5)\n",
    "    res = np.nanmean(res, axis=-1)\n",
    "    return res\n",
    "\n",
    "def l2_err_competitor(vals: np.ndarray, other: np.ndarray = None):\n",
    "    vals[np.isnan(vals)] = 0.0\n",
    "    if other is None:\n",
    "        diff = vals\n",
    "    else:\n",
    "        diff = vals - other\n",
    "    res = compute_l2_err(diff)\n",
    "    assert res.shape == (N_SIZES, N_PICKS)\n",
    "    data = []\n",
    "    for (size_ix, size) in enumerate(SIZES):\n",
    "        for pick in range(N_PICKS):\n",
    "            data.append(dict(experiment=pick, training=0, sample_size=size, error=res[size_ix, pick]))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "lfcs_errs_deseq2 = l2_err_competitor(other_predictions[\"deseq2\"][\"lfc\"], other=lfc_gt).assign(algorithm=\"DESeq2\")\n",
    "lfcs_errs_edger = l2_err_competitor(other_predictions[\"edger\"][\"lfc\"], other=lfc_gt).assign(algorithm=\"EdgeR\")\n",
    "lfcs_errs_mast = l2_err_competitor(other_predictions[\"mast\"][\"lfc\"], other=lfc_gt).assign(algorithm=\"MAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_l2_err(my_df):\n",
    "    diff = my_df.sort_values(\"gene\")[\"lfc_mean\"] - lfc_gt\n",
    "    error = 0.5 * (diff ** 2) ** (0.5)\n",
    "    error = np.nanmean(error)\n",
    "    return pd.Series(dict(error=error))\n",
    "\n",
    "lfcs_errs_mf = (\n",
    "    res_mf\n",
    "    .groupby([\"experiment\", \"sample_size\", \"training\", \"algorithm\"])\n",
    "    .apply(pd_l2_err)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "lfcs_errs_iaf = (\n",
    "    res_iaf\n",
    "    .groupby([\"experiment\", \"sample_size\", \"training\", \"algorithm\"])\n",
    "    .apply(pd_l2_err)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errs = pd.concat([\n",
    "    lfcs_errs_mf,\n",
    "    lfcs_errs_iaf,\n",
    "    lfcs_errs_deseq2,\n",
    "    lfcs_errs_edger,\n",
    "    lfcs_errs_mast,\n",
    "], ignore_index=True)\n",
    "\n",
    "px.box(all_errs, x=\"sample_size\", y=\"error\", color=\"algorithm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iw_vae = IAVAE(\n",
    "#     dataset.nb_genes, n_batch=dataset.n_batches, n_hidden=32, n_layers=1, do_h=True, n_latent=10, t=4\n",
    "# )\n",
    "# iw_trainer = UnsupervisedTrainer(\n",
    "#     iw_vae, dataset, ratio_loss=True, k_importance_weighted=5, single_backward=False\n",
    "# )\n",
    "# iw_trainer.train(n_epochs=50, lr=1e-3)\n",
    "# iw_trainer.train_losses\n",
    "\n",
    "iw_vae = VAE(\n",
    "    dataset.nb_genes, n_batch=dataset.n_batches, n_hidden=128, n_layers=1, n_latent=10\n",
    ")\n",
    "iw_trainer = UnsupervisedTrainer(\n",
    "    iw_vae, dataset, ratio_loss=True, k_importance_weighted=5, single_backward=False\n",
    ")\n",
    "iw_trainer.train(n_epochs=50, lr=1e-3)\n",
    "iw_trainer.train_losses\n",
    "\n",
    "\n",
    "\n",
    "vae = VAE(\n",
    "    dataset.nb_genes, n_batch=dataset.n_batches, n_hidden=128, n_layers=1, n_latent=10\n",
    ")\n",
    "trainer = UnsupervisedTrainer(\n",
    "    vae, dataset, ratio_loss=True, #k_importance_weighted=5, single_backward=False\n",
    ")\n",
    "trainer.train(n_epochs=50, lr=1e-3)\n",
    "trainer.train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iw = iw_trainer.test_set\n",
    "test_mf = trainer.test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfc(post):\n",
    "    z_iaf, labels_iaf, scales_iaf = post.get_latents(n_samples=100, other='scales', device=\"cpu\")\n",
    "    where_a = np.where(labels_iaf == label_a)[0][:100]\n",
    "    where_b = np.where(labels_iaf == label_b)[0][:100]\n",
    "\n",
    "    scales_a = scales_iaf[:, where_a, :]\n",
    "    scales_b = scales_iaf[:, where_b, :]\n",
    "\n",
    "    lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "    lfc = lfc.reshape((-1, n_genes))\n",
    "    lfc = np.array(lfc)\n",
    "    return (np.abs(lfc) >= DELTA).mean(0)\n",
    "\n",
    "de_probas_iw = get_lfc(test_iw)\n",
    "de_probas_mf = get_lfc(test_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_pr(fig, preds, y_true, name):\n",
    "    average_precision = average_precision_score(y_true, preds)\n",
    "    preds[np.isnan(preds)] = np.min(preds[~np.isnan(preds)])\n",
    "    precs, recs, _ = precision_recall_curve(y_true=y_true, probas_pred=preds)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=recs,\n",
    "            y=precs,\n",
    "            name=name+'@AP: {0:0.2f}'.format(average_precision)\n",
    "        )\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "plot_pr(fig=fig, preds=de_probas_iw, y_true=is_significant_de, name='IW IAF')\n",
    "plot_pr(fig=fig, preds=de_probas_mf, y_true=is_significant_de, name='MF')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "600.266px",
    "left": "21.9688px",
    "top": "110px",
    "width": "239.156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
