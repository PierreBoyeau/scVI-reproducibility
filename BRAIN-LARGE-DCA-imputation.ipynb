{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from dca.api import dca\n",
    "import anndata\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ubuntu/single-cell-scVI/data/10x1M/data_small.hdf5\"\n",
    "f = h5py.File(data_path)\n",
    "expression_train = f[\"data_train\"][:10000]\n",
    "expression_test = f[\"data_test\"][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ubuntu/single-cell-scVI/data/10x1M/\"\n",
    "X_zero, i, j, ix = \\\n",
    "        np.load(data_path + \"imputation/X_zero.npy\"), np.load(data_path + \"imputation/i.npy\"),\\\n",
    "        np.load(data_path + \"imputation/j.npy\"), np.load(data_path + \"imputation/ix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCA: Successfully preprocessed 720 genes and 10000 cells.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "count (InputLayer)              (None, 720)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc0 (Dense)                    (None, 64)           46144       count[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           192         enc0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "enc0_act (Activation)           (None, 64)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "center (Dense)                  (None, 32)           2080        enc0_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32)           96          center[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_act (Activation)         (None, 32)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dec1 (Dense)                    (None, 64)           2112        center_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           192         dec1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dec1_act (Activation)           (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mean (Dense)                    (None, 720)          46800       dec1_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "size_factors (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 720)          0           mean[0][0]                       \n",
      "                                                                 size_factors[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dispersion (Dense)              (None, 720)          46800       dec1_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pi (Dense)                      (None, 720)          46800       dec1_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "slice (SliceLayer)              (None, 720)          0           output[0][0]                     \n",
      "                                                                 dispersion[0][0]                 \n",
      "                                                                 pi[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 191,216\n",
      "Trainable params: 190,896\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/300\n",
      "9000/9000 [==============================] - 4s 409us/step - loss: 1.8487 - val_loss: 1.6693\n",
      "Epoch 2/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.6580 - val_loss: 1.6278\n",
      "Epoch 3/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.6380 - val_loss: 1.6158\n",
      "Epoch 4/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.6293 - val_loss: 1.6097\n",
      "Epoch 5/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6232 - val_loss: 1.6048\n",
      "Epoch 6/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6201 - val_loss: 1.6039\n",
      "Epoch 7/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6171 - val_loss: 1.6021\n",
      "Epoch 8/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.6144 - val_loss: 1.5987\n",
      "Epoch 9/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.6123 - val_loss: 1.5971\n",
      "Epoch 10/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.6103 - val_loss: 1.5991\n",
      "Epoch 11/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.6097 - val_loss: 1.5970\n",
      "Epoch 12/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6079 - val_loss: 1.5954\n",
      "Epoch 13/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6067 - val_loss: 1.5959\n",
      "Epoch 14/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.6055 - val_loss: 1.5954\n",
      "Epoch 15/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.6037 - val_loss: 1.5936\n",
      "Epoch 16/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6033 - val_loss: 1.5916\n",
      "Epoch 17/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.6030 - val_loss: 1.5969\n",
      "Epoch 18/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.6017 - val_loss: 1.5924\n",
      "Epoch 19/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6015 - val_loss: 1.5912\n",
      "Epoch 20/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.6002 - val_loss: 1.5928\n",
      "Epoch 21/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5996 - val_loss: 1.5908\n",
      "Epoch 22/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5994 - val_loss: 1.5908\n",
      "Epoch 23/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5982 - val_loss: 1.5880\n",
      "Epoch 24/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5976 - val_loss: 1.5875\n",
      "Epoch 25/300\n",
      "9000/9000 [==============================] - 3s 294us/step - loss: 1.5975 - val_loss: 1.5923\n",
      "Epoch 26/300\n",
      "9000/9000 [==============================] - 3s 294us/step - loss: 1.5961 - val_loss: 1.5856\n",
      "Epoch 27/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5961 - val_loss: 1.5867\n",
      "Epoch 28/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5951 - val_loss: 1.5860\n",
      "Epoch 29/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5945 - val_loss: 1.5878\n",
      "Epoch 30/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5940 - val_loss: 1.5866\n",
      "Epoch 31/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5949 - val_loss: 1.5895\n",
      "Epoch 32/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5939 - val_loss: 1.5860\n",
      "Epoch 33/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5932 - val_loss: 1.5854\n",
      "Epoch 34/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5927 - val_loss: 1.5864\n",
      "Epoch 35/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5925 - val_loss: 1.5864\n",
      "Epoch 36/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5921 - val_loss: 1.5850\n",
      "Epoch 37/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5918 - val_loss: 1.5852\n",
      "Epoch 38/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5918 - val_loss: 1.5879\n",
      "Epoch 39/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5911 - val_loss: 1.5841\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 3s 294us/step - loss: 1.5907 - val_loss: 1.5849\n",
      "Epoch 41/300\n",
      "9000/9000 [==============================] - 3s 294us/step - loss: 1.5901 - val_loss: 1.5867\n",
      "Epoch 42/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5903 - val_loss: 1.5842\n",
      "Epoch 43/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5898 - val_loss: 1.5876\n",
      "Epoch 44/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5898 - val_loss: 1.5839\n",
      "Epoch 45/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5894 - val_loss: 1.5853\n",
      "Epoch 46/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5892 - val_loss: 1.5822\n",
      "Epoch 47/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5889 - val_loss: 1.5823\n",
      "Epoch 48/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5886 - val_loss: 1.5836\n",
      "Epoch 49/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5882 - val_loss: 1.5819\n",
      "Epoch 50/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5878 - val_loss: 1.5835\n",
      "Epoch 51/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5875 - val_loss: 1.5809\n",
      "Epoch 52/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5874 - val_loss: 1.5801\n",
      "Epoch 53/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5874 - val_loss: 1.5839\n",
      "Epoch 54/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5870 - val_loss: 1.5827\n",
      "Epoch 55/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5873 - val_loss: 1.5817\n",
      "Epoch 56/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5871 - val_loss: 1.5799\n",
      "Epoch 57/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5868 - val_loss: 1.5855\n",
      "Epoch 58/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5865 - val_loss: 1.5808\n",
      "Epoch 59/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5868 - val_loss: 1.5822\n",
      "Epoch 60/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5857 - val_loss: 1.5795\n",
      "Epoch 61/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5858 - val_loss: 1.5819\n",
      "Epoch 62/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5854 - val_loss: 1.5803\n",
      "Epoch 63/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5856 - val_loss: 1.5798\n",
      "Epoch 64/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5861 - val_loss: 1.5888\n",
      "Epoch 65/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5855 - val_loss: 1.5808\n",
      "Epoch 66/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5856 - val_loss: 1.5799\n",
      "Epoch 67/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5848 - val_loss: 1.5835\n",
      "Epoch 68/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5850 - val_loss: 1.5802\n",
      "Epoch 69/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5850 - val_loss: 1.5798\n",
      "Epoch 70/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5846 - val_loss: 1.5792\n",
      "Epoch 71/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5839 - val_loss: 1.5795\n",
      "Epoch 72/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5844 - val_loss: 1.5799\n",
      "Epoch 73/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5850 - val_loss: 1.5813\n",
      "Epoch 74/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5847 - val_loss: 1.5793\n",
      "Epoch 75/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5844 - val_loss: 1.5807\n",
      "Epoch 76/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5840 - val_loss: 1.5801\n",
      "Epoch 77/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5835 - val_loss: 1.5810\n",
      "Epoch 78/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5836 - val_loss: 1.5785\n",
      "Epoch 79/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5828 - val_loss: 1.5780\n",
      "Epoch 80/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5833 - val_loss: 1.5779\n",
      "Epoch 81/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.5831 - val_loss: 1.5816\n",
      "Epoch 82/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5833 - val_loss: 1.5786\n",
      "Epoch 83/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.5829 - val_loss: 1.5783\n",
      "Epoch 84/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.5828 - val_loss: 1.5788\n",
      "Epoch 85/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.5829 - val_loss: 1.5807\n",
      "Epoch 86/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5826 - val_loss: 1.5775\n",
      "Epoch 87/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5824 - val_loss: 1.5771\n",
      "Epoch 88/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5823 - val_loss: 1.5784\n",
      "Epoch 89/300\n",
      "9000/9000 [==============================] - 3s 299us/step - loss: 1.5831 - val_loss: 1.5768\n",
      "Epoch 90/300\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 1.5823 - val_loss: 1.5779\n",
      "Epoch 91/300\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 1.5822 - val_loss: 1.5782\n",
      "Epoch 92/300\n",
      "9000/9000 [==============================] - 3s 304us/step - loss: 1.5821 - val_loss: 1.5770\n",
      "Epoch 93/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5817 - val_loss: 1.5822\n",
      "Epoch 94/300\n",
      "9000/9000 [==============================] - 3s 299us/step - loss: 1.5818 - val_loss: 1.5769\n",
      "Epoch 95/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5813 - val_loss: 1.5769\n",
      "Epoch 96/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5812 - val_loss: 1.5766\n",
      "Epoch 97/300\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 1.5819 - val_loss: 1.5783\n",
      "Epoch 98/300\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 1.5810 - val_loss: 1.5762\n",
      "Epoch 99/300\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 1.5813 - val_loss: 1.5767\n",
      "Epoch 100/300\n",
      "9000/9000 [==============================] - 3s 306us/step - loss: 1.5813 - val_loss: 1.5788\n",
      "Epoch 101/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.5811 - val_loss: 1.5773\n",
      "Epoch 102/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5811 - val_loss: 1.5787\n",
      "Epoch 103/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.5809 - val_loss: 1.5764\n",
      "Epoch 104/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5810 - val_loss: 1.5840\n",
      "Epoch 105/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5810 - val_loss: 1.5759\n",
      "Epoch 106/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5807 - val_loss: 1.5763\n",
      "Epoch 107/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5813 - val_loss: 1.5760\n",
      "Epoch 108/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5804 - val_loss: 1.5772\n",
      "Epoch 109/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5804 - val_loss: 1.5777\n",
      "Epoch 110/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5804 - val_loss: 1.5825\n",
      "Epoch 111/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5805 - val_loss: 1.5755\n",
      "Epoch 112/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5803 - val_loss: 1.5760\n",
      "Epoch 113/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5801 - val_loss: 1.5763\n",
      "Epoch 114/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5797 - val_loss: 1.5749\n",
      "Epoch 115/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5801 - val_loss: 1.5755\n",
      "Epoch 116/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5799 - val_loss: 1.5769\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5802 - val_loss: 1.5757\n",
      "Epoch 118/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5799 - val_loss: 1.5757\n",
      "Epoch 119/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5798 - val_loss: 1.5754\n",
      "Epoch 120/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5801 - val_loss: 1.5770\n",
      "Epoch 121/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5802 - val_loss: 1.5765\n",
      "Epoch 122/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5797 - val_loss: 1.5747\n",
      "Epoch 123/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5798 - val_loss: 1.5747\n",
      "Epoch 124/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5801 - val_loss: 1.5802\n",
      "Epoch 125/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5796 - val_loss: 1.5752\n",
      "Epoch 126/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5790 - val_loss: 1.5749\n",
      "Epoch 127/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5792 - val_loss: 1.5747\n",
      "Epoch 128/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5793 - val_loss: 1.5751\n",
      "Epoch 129/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5788 - val_loss: 1.5759\n",
      "Epoch 130/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5790 - val_loss: 1.5755\n",
      "Epoch 131/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5792 - val_loss: 1.5758\n",
      "Epoch 132/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5787 - val_loss: 1.5747\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 133/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5747 - val_loss: 1.5702\n",
      "Epoch 134/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5741 - val_loss: 1.5701\n",
      "Epoch 135/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5741 - val_loss: 1.5700\n",
      "Epoch 136/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5741 - val_loss: 1.5699\n",
      "Epoch 137/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5737 - val_loss: 1.5698\n",
      "Epoch 138/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5740 - val_loss: 1.5696\n",
      "Epoch 139/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5735 - val_loss: 1.5698\n",
      "Epoch 140/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5737 - val_loss: 1.5697\n",
      "Epoch 141/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5732 - val_loss: 1.5698\n",
      "Epoch 142/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5736 - val_loss: 1.5696\n",
      "Epoch 143/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5735 - val_loss: 1.5699\n",
      "Epoch 144/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5735 - val_loss: 1.5696\n",
      "Epoch 145/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5736 - val_loss: 1.5695\n",
      "Epoch 146/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5735 - val_loss: 1.5697\n",
      "Epoch 147/300\n",
      "9000/9000 [==============================] - 3s 295us/step - loss: 1.5731 - val_loss: 1.5696\n",
      "Epoch 148/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.5734 - val_loss: 1.5696\n",
      "Epoch 149/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5737 - val_loss: 1.5697\n",
      "Epoch 150/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5735 - val_loss: 1.5696\n",
      "Epoch 151/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5735 - val_loss: 1.5699\n",
      "Epoch 152/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5732 - val_loss: 1.5696\n",
      "Epoch 153/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5732 - val_loss: 1.5697\n",
      "Epoch 154/300\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 1.5734 - val_loss: 1.5695\n",
      "Epoch 155/300\n",
      "9000/9000 [==============================] - 3s 299us/step - loss: 1.5731 - val_loss: 1.5697\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 156/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5728 - val_loss: 1.5695\n",
      "Epoch 157/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5726 - val_loss: 1.5695\n",
      "Epoch 158/300\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.5729 - val_loss: 1.5695\n",
      "Epoch 159/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5725 - val_loss: 1.5694\n",
      "Epoch 160/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5729 - val_loss: 1.5694\n",
      "Epoch 161/300\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.5725 - val_loss: 1.5694\n",
      "Epoch 162/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5729 - val_loss: 1.5693\n",
      "Epoch 163/300\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 164/300\n",
      "9000/9000 [==============================] - 3s 300us/step - loss: 1.5725 - val_loss: 1.5694\n",
      "Epoch 165/300\n",
      "9000/9000 [==============================] - 3s 303us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 166/300\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.5729 - val_loss: 1.5695\n",
      "Epoch 167/300\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 1.5729 - val_loss: 1.5695\n",
      "Epoch 168/300\n",
      "9000/9000 [==============================] - 3s 303us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 169/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5723 - val_loss: 1.5693\n",
      "Epoch 170/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5728 - val_loss: 1.5694\n",
      "Epoch 171/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5725 - val_loss: 1.5693\n",
      "Epoch 172/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5729 - val_loss: 1.5694\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 173/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5727 - val_loss: 1.5695\n",
      "Epoch 174/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5729 - val_loss: 1.5694\n",
      "Epoch 175/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5723 - val_loss: 1.5694\n",
      "Epoch 176/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5728 - val_loss: 1.5694\n",
      "Epoch 177/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5726 - val_loss: 1.5693\n",
      "Epoch 178/300\n",
      "9000/9000 [==============================] - 3s 288us/step - loss: 1.5728 - val_loss: 1.5694\n",
      "Epoch 179/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 180/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 181/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5729 - val_loss: 1.5693\n",
      "Epoch 182/300\n",
      "9000/9000 [==============================] - 3s 290us/step - loss: 1.5731 - val_loss: 1.5695\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 183/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5728 - val_loss: 1.5694\n",
      "Epoch 184/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5727 - val_loss: 1.5693\n",
      "Epoch 185/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5725 - val_loss: 1.5694\n",
      "Epoch 186/300\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 187/300\n",
      "9000/9000 [==============================] - 3s 293us/step - loss: 1.5732 - val_loss: 1.5694\n",
      "Epoch 188/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5730 - val_loss: 1.5694\n",
      "Epoch 189/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5723 - val_loss: 1.5693\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 191/300\n",
      "9000/9000 [==============================] - 3s 292us/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 192/300\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 1.5727 - val_loss: 1.5694\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 00192: early stopping\n",
      "Calculating low dimensional representations...\n",
      "Calculating reconstructions...\n"
     ]
    }
   ],
   "source": [
    "train = anndata.AnnData(X_zero)\n",
    "res = dca(train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0506168603897095"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_index = i[ix], j[ix]\n",
    "x, y = train.X[all_index], expression_train[all_index]\n",
    "np.median(np.abs(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
