{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "from chart_studio.plotly import plot, iplot\n",
    "\n",
    "# from plotly.offline import init_notebook_mode, iplot\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scvi.dataset import PowSimSynthetic, LatentLogPoissonDataset\n",
    "from scvi.models import VAE, IAVAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.utils import demultiply, make_dir_if_necessary, predict_de_genes\n",
    "from scvi_utils import estimate_de_proba, estimate_lfc_density, estimate_lfc_mean\n",
    "from R_interop import all_predictions\n",
    "\n",
    "\n",
    "N_EPOCHS = 1\n",
    "DELTA = 0.5\n",
    "SIZES = [5, 10, 20, 30, 50, 100]\n",
    "SIZE = 100\n",
    "N_SIZES = len(SIZES)\n",
    "\n",
    "Q0 = 5e-2\n",
    "N_TRAININGS = 1\n",
    "N_PICKS = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "DIR_PATH = 'lfc_estimates/powsimr'\n",
    "make_dir_if_necessary(DIR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PowSimSynthetic(\n",
    "    cluster_to_samples=[7500, 7500],\n",
    "    de_p=0.5,\n",
    "    n_genes=1500,\n",
    "    mode=\"NB\",\n",
    "#     n_genes_zi=250,\n",
    "#     p_dropout=0.3,\n",
    ")\n",
    "\n",
    "is_significant_de = np.abs(dataset.lfc[:, 1] - dataset.lfc[:, 0]) >= DELTA\n",
    "n_genes = dataset.nb_genes\n",
    "trace1 = go.Histogram(x=dataset.lfc[:, 1] - dataset.lfc[:, 0])\n",
    "fig = go.Figure(data=[trace1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = len(dataset)\n",
    "TEST_INDICES = np.random.np.random.permutation(n_examples)[:2000]\n",
    "\n",
    "x_test, y_test = dataset.X[TEST_INDICES, :], dataset.labels[TEST_INDICES, :].squeeze()\n",
    "data_path = os.path.join(DIR_PATH, 'data.npy')\n",
    "labels_path = os.path.join(DIR_PATH, 'labels.npy')\n",
    "\n",
    "np.save(\n",
    "    data_path,\n",
    "    x_test.squeeze().astype(int)\n",
    ")\n",
    "np.savetxt(\n",
    "    labels_path,\n",
    "    y_test.squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute competitors scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_predictions = all_predictions(\n",
    "    n_genes=n_genes, \n",
    "    n_picks=N_PICKS, \n",
    "    sizes=SIZES, \n",
    "    data_path=data_path, \n",
    "    labels_path=labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR / Power Control and PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    mdl_class, dataset, mdl_params: dict, train_params: dict, train_fn_params: dict\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    :param mdl_class: Class of algorithm\n",
    "    :param dataset: Dataset\n",
    "    :param mdl_params:\n",
    "    :param train_params:\n",
    "    :param train_fn_params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    my_vae = mdl_class(dataset.nb_genes, n_batch=dataset.n_batches, **mdl_params)\n",
    "    my_trainer = UnsupervisedTrainer(my_vae, dataset, **train_params)\n",
    "    print(my_trainer.test_set.data_loader.sampler.indices)\n",
    "    my_trainer.train(**train_fn_params)\n",
    "    print(my_trainer.train_losses)\n",
    "    return my_vae, my_trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FDR and TPR Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "de_probas_mf = estimate_de_proba(\n",
    "    VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, n_latent=5),\n",
    "    train_params=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-4),\n",
    "    sizes=SIZES,\n",
    "    n_trainings=N_TRAININGS,\n",
    "    n_picks=N_PICKS,\n",
    ")\n",
    "de_probas_ia = estimate_de_proba(\n",
    "    IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=5, t=4),\n",
    "    train_params=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-4),\n",
    "    sizes=SIZES,\n",
    "    n_trainings=N_TRAININGS,\n",
    "    n_picks=N_PICKS,\n",
    ")\n",
    "# results_mf5 = fdr_control(\n",
    "#     VAE,\n",
    "#     mdl_params=dict(n_hidden=128, n_layers=1, n_latent=5),\n",
    "#     train_params=dict(\n",
    "#         train_size=0.7, ratio_loss=True, k_importance_weighted=5, single_backward=False\n",
    "#     ),\n",
    "#     train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-4),\n",
    "#     n_trainings=N_TRAININGS,\n",
    "#     n_picks=N_PICKS,\n",
    "# )\n",
    "# results_mf50tr = fdr_control(\n",
    "#     VAE,\n",
    "#     mdl_params=dict(n_hidden=64, n_layers=3, n_latent=5),\n",
    "#     train_params=dict(train_size=0.7, ratio_loss=True, k_importance_weighted=25),\n",
    "#     train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-4),\n",
    "#     n_trainings=N_TRAININGS,\n",
    "#     n_picks=N_PICKS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(probas_arr, is_significant_de):\n",
    "    fdrs = np.zeros((N_TRAININGS, len(SIZES), N_PICKS))\n",
    "    fnrs = np.zeros((N_TRAININGS, len(SIZES), N_PICKS))\n",
    "    for i in range(N_TRAININGS):\n",
    "        for j in range(len(SIZES)):\n",
    "            for k in range(N_PICKS):\n",
    "                probs_pred_de = probas_arr[i, j, k, :]\n",
    "                is_pred_de = predict_de_genes(probs_pred_de, desired_fdr=Q0)\n",
    "                \n",
    "                true_fdr = ((~is_significant_de) * is_pred_de).sum() / len(probs_pred_de)\n",
    "                n_positives = is_significant_de.sum()\n",
    "                true_fnr = (is_significant_de * (~is_pred_de)).sum() / n_positives\n",
    "                fdrs[i, j, k] = true_fdr\n",
    "                fnrs[i, j, k] = true_fnr\n",
    "    return dict(fdr=fdrs, fnr=fnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_mf = compute_stats(de_probas_mf, is_significant_de=is_significant_de)\n",
    "results_ia = compute_stats(de_probas_ia, is_significant_de=is_significant_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = [\n",
    "    results_mf,\n",
    "    results_ia,\n",
    "]\n",
    "names = [\n",
    "    \"MF\",\n",
    "    \"IAF\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated_sizes = np.array(SIZES).reshape((1, -1))\n",
    "associated_sizes = np.tile(associated_sizes, [N_TRAININGS, 1])\n",
    "\n",
    "all_dfs = []\n",
    "for result, name in zip(all_results, names):\n",
    "    fdrs = result[\"fdr\"]\n",
    "    fnrs = result[\"fnr\"]\n",
    "    fdrs[np.isnan(fdrs)] = 0.0\n",
    "    new_df = pd.DataFrame(\n",
    "        dict(\n",
    "            fdr=fdrs.mean(-1).reshape(-1), \n",
    "            size=associated_sizes.reshape(-1), \n",
    "            fnr=fnrs.mean(-1).reshape(-1)\n",
    "        )\n",
    "    ).assign(posterior=lambda x: name)\n",
    "    all_dfs.append(new_df)\n",
    "\n",
    "df = pd.concat(all_dfs, ignore_index=True).dropna()\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    df,\n",
    "    x=\"size\",\n",
    "    y=\"fdr\",\n",
    "    color=\"posterior\",\n",
    "    title=\"Control on False Discovery Rate\",\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"fdr_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    df,\n",
    "    x=\"size\",\n",
    "    y=\"fdr\",\n",
    "    color=\"posterior\",\n",
    "    title=\"Control on False Discovery Rate\",\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"fdr_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    df,\n",
    "    x=\"size\",\n",
    "    y=\"fnr\",\n",
    "    color=\"posterior\",\n",
    "    title=\"Control on False Negative Rate\",\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename=\"fdr_control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trains_res = all_fdrs.mean(axis=1)\n",
    "print(trains_res.mean(), trains_res.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds_1d = y_preds.reshape((-1, dataset.nb_genes))\n",
    "n_exps = len(y_preds_1d)\n",
    "confs = np.zeros((n_exps, 2, 2))\n",
    "for i in range(n_exps):\n",
    "    confs[i, :, :] = confusion_matrix(is_significant_de, y_preds_1d[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(is_significant_de, y_preds_1d[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confs_mean = confs.mean(0)\n",
    "confs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = ff.create_annotated_heatmap(\n",
    "    z=confs_mean, x=[\"Pred Negative\", \"Pred Positive\"], y=[\"GT Negative\", \"GT Positive\"]\n",
    ")\n",
    "fig.update({\"layout\": dict(title=\"Confusion Matrix\")})\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "de_probas_mf.shape\n",
    "de_probas_ia.shape\n",
    "print(other_predictions['mast']['pval'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "preds_md = 1.0 - de_probas_mf[0, -1, 0, :]\n",
    "preds_iaf = 1.0 - de_probas_ia[0, -1, 0, :]\n",
    "preds_deseq2 = 1.0 - other_predictions['deseq2']['pval'][-1, 0, :]\n",
    "preds_edger = 1.0 - other_predictions['edger']['pval'][-1, 0, :]\n",
    "preds_mast = 1.0 - other_predictions['mast']['pval'][-1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_pr(fig, preds, y_true, name):\n",
    "    average_precision = average_precision_score(y_true, preds)\n",
    "    preds[np.isnan(preds)] = np.min(preds[~np.isnan(preds)])\n",
    "    precs, recs, _ = precision_recall_curve(y_true=y_true, probas_pred=preds)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=recs,\n",
    "            y=precs,\n",
    "            name=name+'@AP: {0:0.2f}'.format(average_precision)\n",
    "        )\n",
    "    )\n",
    "    return\n",
    "layout = go.Layout(\n",
    "    title='Precision Recall Curves',\n",
    "    xaxis=dict(title='Recall'),\n",
    "    yaxis=dict(title='Precision'),\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig = go.Figure(layout=layout)\n",
    "plot_pr(fig=fig, preds=preds_md, y_true=is_significant_de, name='MF')\n",
    "plot_pr(fig=fig, preds=preds_iaf, y_true=is_significant_de, name='IAF')\n",
    "plot_pr(fig=fig, preds=preds_deseq2, y_true=is_significant_de, name='DESeq2')\n",
    "plot_pr(fig=fig, preds=preds_edger, y_true=is_significant_de, name='EdgeR')\n",
    "plot_pr(fig=fig, preds=preds_mast, y_true=is_significant_de, name='MAST')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonal Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_gt = -(dataset.lfc[:, 1] - dataset.lfc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_mf = estimate_lfc_density(\n",
    "    VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, n_latent=5),\n",
    "    train_params=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    sizes=[SIZE],\n",
    "    n_picks=1,\n",
    ")[SIZE]\n",
    "\n",
    "lfcs_ia = estimate_lfc_density(\n",
    "    IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=5, t=4),\n",
    "    train_params=dict(ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    sizes=[SIZE],\n",
    "    n_picks=1,\n",
    ")[SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot diagonal curve showing quality of LFC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "lfcs_mf_est = lfcs_ia.reshape((-1, n_genes))\n",
    "lfcs_ia_est = lfcs_mf.reshape((-1, n_genes))\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Mean Field\", \"Inverse Autoregressive Flows\"),\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_plot(fig, lfcs_est_m, lfcs_est_err, row, col):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lfc_gt,\n",
    "            y=lfcs_est_m,\n",
    "            error_y=dict(type=\"data\", array=lfcs_est_err, visible=True),\n",
    "            mode=\"markers\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "add_plot(fig, lfcs_mf_est.mean(0), lfcs_mf_est.std(0), row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "add_plot(fig, lfcs_ia_est.mean(0), lfcs_ia_est.std(0), row=1, col=2)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-3, 3],\n",
    "        y=[-3, 3],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Ground Truth LFC\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Ground Truth LFC\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Predicted LFC\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Predicted LFC\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600, width=1000, title_text=\"LFC estimation for {} sample cells\".format(sz)\n",
    ")\n",
    "fig.show()\n",
    "# iplot(fig, filename='lfc_with_uncertainty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of LFC errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc_gt = -(dataset.lfc[:, 1] - dataset.lfc[:, 0])\n",
    "\n",
    "def l2_err(vals: np.ndarray, other: np.ndarray = None):\n",
    "    if other is None:\n",
    "        diff = vals\n",
    "    else:\n",
    "        diff = vals - other\n",
    "    res = 0.5 * (diff ** 2) ** (0.5)\n",
    "    res = np.nanmean(res, axis=-1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_pred_mf = estimate_lfc_mean(\n",
    "    VAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, n_latent=5),\n",
    "    train_params=dict(train_size=0.7, ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    sizes=SIZES,\n",
    "    n_picks=N_PICKS,\n",
    ")\n",
    "\n",
    "lfcs_pred_ia = estimate_lfc_mean(\n",
    "    IAVAE,\n",
    "    dataset=dataset,\n",
    "    mdl_params=dict(n_hidden=128, n_layers=1, do_h=True, n_latent=5, t=4),\n",
    "    train_params=dict(train_size=0.7, ratio_loss=True, test_indices=TEST_INDICES),\n",
    "    train_fn_params=dict(n_epochs=N_EPOCHS, lr=1e-3),\n",
    "    sizes=SIZES,\n",
    "    n_picks=N_PICKS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_errs_mf = np.array([l2_err(arr, other=lfc_gt) for (size, arr) in lfcs_pred_mf.items()])\n",
    "lfcs_errs_ia = np.array([l2_err(arr, other=lfc_gt) for (size, arr) in lfcs_pred_ia.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lfcs_errs_mf.shape, other_predictions[\"deseq2\"]['lfc'].shape, lfc_gt.shape, lfcs_pred_mf[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_pred_mf[100] - lfc_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcs_errs_deseq2 = l2_err(other_predictions[\"deseq2\"][\"lfc\"], other=lfc_gt)\n",
    "lfcs_errs_edger = l2_err(other_predictions[\"edger\"][\"lfc\"], other=lfc_gt)\n",
    "lfcs_errs_mast = l2_err(other_predictions[\"mast\"][\"lfc\"], other=lfc_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predictions[\"deseq2\"][\"lfc\"][-1, 0] - lfc_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_err(other_predictions[\"deseq2\"][\"lfc\"][-1, 0], lfc_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lfcs_errs_mf.shape == (N_SIZES, N_PICKS)\n",
    "assert lfcs_errs_deseq2.shape == (N_SIZES, N_PICKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_errors(fig, errors, color=\"red\", name=\"\"):\n",
    "    \"\"\"\n",
    "        errors should be (n_sizes, n_picks)\n",
    "    \"\"\"\n",
    "    errs_mean = errors.mean(1)\n",
    "    errs_std = errors.std(1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=SIZES,\n",
    "            y=errs_mean - errs_std,\n",
    "            mode=\"lines\",\n",
    "            line_color=color,\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=SIZES,\n",
    "            y=errs_mean + errs_std,\n",
    "            line_color=color,\n",
    "            mode=\"lines\",\n",
    "            fill=\"tonexty\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=SIZES, y=errs_mean, line_color=color, mode=\"lines+markers\", name=name\n",
    "        )\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.update_layout(\n",
    "    title=go.layout.Title(text=\"L2 LFC Prediction Error\"),\n",
    "    xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=\"Number of sampled cells\")),\n",
    "    yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=\"Error\")),\n",
    ")\n",
    "\n",
    "plot_errors(fig, lfcs_errs_mf, name=\"Mean Field\")\n",
    "plot_errors(fig, lfcs_errs_ia, color=\"blue\", name=\"IAF\")\n",
    "\n",
    "plot_errors(fig, lfcs_errs_deseq2, color=\"green\" , name=\"DESeq2\")\n",
    "plot_errors(fig, lfcs_errs_edger, color=\"purple\" , name=\"EdgeR\")\n",
    "plot_errors(fig, lfcs_errs_mast, color=\"orange\" , name=\"MAST\")\n",
    "fig.show()\n",
    "# iplot(fig, filename='lfc_size_influence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# trace1 = go.Histogram(x=dataset.X.mean(0))\n",
    "# fig = go.Figure(data=[trace1])\n",
    "# fig.show()\n",
    "\n",
    "# dataset.X\n",
    "\n",
    "# # from torch.autograd import set_detect_anomaly\n",
    "# # set_detect_anomaly(True)\n",
    "\n",
    "# vae = VAE(\n",
    "#     dataset.nb_genes, n_batch=dataset.n_batches, n_hidden=128, n_layers=1, n_latent=5\n",
    "# )\n",
    "# trainer = UnsupervisedTrainer(\n",
    "#     vae, dataset, ratio_loss=True, k_importance_weighted=5, single_backward=False\n",
    "# )\n",
    "# trainer.train(n_epochs=50, lr=1e-3)\n",
    "\n",
    "# trainer.train_losses\n",
    "\n",
    "# iw_vae = VAE(\n",
    "#     dataset.nb_genes, n_batch=dataset.n_batches, n_hidden=128, n_layers=1, n_latent=5\n",
    "# )\n",
    "# iw_trainer = UnsupervisedTrainer(\n",
    "#     iw_vae, dataset, ratio_loss=True, k_importance_weighted=5, single_backward=False\n",
    "# )\n",
    "# iw_trainer.train(n_epochs=50, lr=1e-3)\n",
    "\n",
    "# iw_trainer.train_losses\n",
    "\n",
    "# iavae = IAVAE(\n",
    "#     dataset.nb_genes,\n",
    "#     n_batch=dataset.n_batches,\n",
    "#     n_hidden=128,\n",
    "#     n_layers=1,\n",
    "#     do_h=True,\n",
    "#     n_latent=5,\n",
    "#     t=4,\n",
    "# )\n",
    "# ia_trainer = UnsupervisedTrainer(iavae, dataset, ratio_loss=True)\n",
    "# ia_trainer.train(n_epochs=100, lr=1e-3)\n",
    "\n",
    "# ia_trainer.train_losses\n",
    "\n",
    "# plt.plot(trainer.train_losses[5:], label=\"MF\")\n",
    "# plt.plot(iw_trainer.train_losses[5:], label=\"IW\")\n",
    "# plt.plot(ia_trainer.train_losses[5:], label=\"IAF\")\n",
    "# # plt.yscale(\"log\")\n",
    "# plt.legend()\n",
    "\n",
    "# ia_trainer.test_set.marginal_ll(n_mc_samples=100, ratio_loss=True)\n",
    "\n",
    "\n",
    "\n",
    "# evidence_mf = trainer.test_set.marginal_ll(n_mc_samples=100, ratio_loss=True)\n",
    "# # evidence_iw = iw_trainer.test_set.marginal_ll(n_mc_samples=100, ratio_loss=True)\n",
    "# evidence_ia = ia_trainer.test_set.marginal_ll(n_mc_samples=100, ratio_loss=True)\n",
    "# print(evidence_mf, evidence_iw, evidence_ia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4395.42928125 4369.418739583333 4391.585421875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The lower the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using very quick experiments (I am waiting for the autotune module), it looks like:\n",
    "\n",
    "MF\n",
    "- 1 layer 16 941.0715670955882\n",
    "- 1 layer 64 935.0418129595588\n",
    "- 1 layer 128 925.3853147977941\n",
    "- 3 layers 32 972.2561259191176\n",
    "\n",
    "IAF\n",
    "- 1 layer 16 950.423221507353\n",
    "- 1 layer 64 928.0418129595588\n",
    "- 1 layer 128 917.7115165441177\n",
    "- 3 layers 32 928.8929044117647\n",
    "- t=4 1 layer 128 915.8975482536765\n",
    "- t=5 1 layer 128 920.9016911764705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Visualizing IAF posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "post = ia_trainer.train_set\n",
    "train_indices = post.data_loader.sampler.indices\n",
    "train_samples = np.random.permutation(train_indices)[:2000]\n",
    "post = ia_trainer.create_posterior(\n",
    "    model=iavae, gene_dataset=dataset, indices=train_samples\n",
    ")\n",
    "z_ia, labels_ia, scales_ia = post.get_latents(n_samples=500, other=True, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# post = trainer.train_set\n",
    "# train_indices = post.data_loader.sampler.indices\n",
    "# train_samples = np.random.permutation(train_indices)[:2000]\n",
    "post = trainer.create_posterior(model=vae, gene_dataset=dataset, indices=train_samples)\n",
    "z, labels, scales = post.get_latents(n_samples=500, other=True, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(labels == labels_ia).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in [5, 10, 100, 1000, 2, 30, 542]:\n",
    "    trace1 = go.Scatter(x=z[:, idx, 0], y=z[:, idx, 1], mode=\"markers\")\n",
    "    trace2 = go.Scatter(x=z_ia[:, idx, 0], y=z_ia[:, idx, 1], mode=\"markers\")\n",
    "    fig = go.Figure([trace1, trace2])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "for my_z in []:\n",
    "    z_mean = my_z.mean(0)\n",
    "    z_tsne = TSNE().fit_transform(z_mean)\n",
    "    #     z_tnse = z_mean\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=z_tnse[:, 0],\n",
    "            y=z_tnse[:, 1],\n",
    "            marker=dict(color=my_lbl.squeeze(), colorscale=\"viridis\"),\n",
    "            mode=\"markers\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_pred_de.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = labels.squeeze()\n",
    "where_a = np.where(labels == 0)[0]\n",
    "where_b = np.where(labels == 1)[0]\n",
    "where_a = where_a[np.random.choice(len(where_a), size=size)]\n",
    "where_b = where_b[np.random.choice(len(where_b), size=size)]\n",
    "scales_a = scales[:, where_a, :].reshape((-1, dataset.nb_genes)).numpy()\n",
    "scales_b = scales[:, where_b, :].reshape((-1, dataset.nb_genes)).numpy()\n",
    "scales_a, scales_b = demultiply(arr1=scales_a, arr2=scales_b, factor=3)\n",
    "lfc = np.log2(scales_a) - np.log2(scales_b)\n",
    "\n",
    "pgs = (np.abs(lfc) >= DELTA).mean(axis=0)\n",
    "sorted_genes = np.argsort(-pgs)\n",
    "sorted_pgs = pgs[sorted_genes]\n",
    "cumulative_fdr = (1.0 - sorted_pgs).cumsum() / (1.0 + np.arange(len(sorted_pgs)))\n",
    "d = (cumulative_fdr <= Q0).sum() - 1\n",
    "pred_de_genes = sorted_genes[:d]\n",
    "is_pred_de = np.zeros_like(cumulative_fdr)\n",
    "is_pred_de[pred_de_genes] = True\n",
    "true_fdr = ((~is_significant_de) * is_pred_de).sum() / len(pred_de_genes)\n",
    "\n",
    "true_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_pred_de.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scales_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted_pgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds_1d = is_pred_de.reshape((-1, dataset.nb_genes))\n",
    "n_exps = len(y_preds_1d)\n",
    "mat = confusion_matrix(is_significant_de, is_pred_de)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
